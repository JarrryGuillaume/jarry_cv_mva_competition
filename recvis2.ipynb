{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbEwgJ2SiUbc",
        "outputId": "2895c27c-d5b4-46fd-c3b4-b25f17202628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'jarry_cv_mva_competition' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/JarrryGuillaume/jarry_cv_mva_competition.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4Y_I8SIdiYLY"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from google.colab import drive\n",
        "sys.path.append(\"jarry_cv_mva_competition\")\n",
        "sys.path.append(\"drive/MyDrive/models\")\n",
        "from IPython.display import clear_output\n",
        "import torch\n",
        "import matplotlib as plt\n",
        "from jarry_cv_mva_competition.main import main\n",
        "from jarry_cv_mva_competition.evaluate import test\n",
        "from jarry_cv_mva_competition.model_factory import ModelFactory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_type = None\n",
        "model_name = \"efficientNet\"\n",
        "model_path = \"drive/MyDrive/experiment/best_\" + model_name + \".pth\"\n",
        "\n",
        "main(\n",
        "         data_folder=\"drive/MyDrive/mva_competition\",\n",
        "         experiment_folder=\"drive/MyDrive/experiment\",\n",
        "         model_name=model_name,\n",
        "         model_path=model_path,\n",
        "         batch_size=128,\n",
        "         num_workers=6,\n",
        "         momentum=0.5,\n",
        "         epochs=100,\n",
        "         seed=42,\n",
        "         lr_body=1e-4,\n",
        "         saving_frequency=5,\n",
        "         log_interval=50,\n",
        "         optimizer=\"Adam\",\n",
        "     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0xWNCdGXCwW",
        "outputId": "fdb65213-f5db-4717-ea98-c1856b1e8acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/content/jarry_cv_mva_competition/model_factory.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(self.model_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfully loaded weights\n",
            "efficientNet used\n",
            "Using GPU\n",
            "Train Epoch: 1 [0/20000 (0%)]\tLoss: 4.634763\n",
            "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 4.609745\n",
            "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 4.818291\n",
            "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 4.437359\n",
            "Epoch : 1, Training accuracy : 16.020000457763672 %\n",
            "Epoch : 1, Validation accuracy : 21.479999542236328 %\n",
            "Train Epoch: 2 [0/20000 (0%)]\tLoss: 4.522413\n",
            "Train Epoch: 2 [6400/20000 (32%)]\tLoss: 4.198117\n",
            "Train Epoch: 2 [12800/20000 (64%)]\tLoss: 4.699409\n",
            "Train Epoch: 2 [19200/20000 (96%)]\tLoss: 4.532085\n",
            "Epoch : 2, Training accuracy : 16.174999237060547 %\n",
            "Epoch : 2, Validation accuracy : 21.559999465942383 %\n",
            "Train Epoch: 3 [0/20000 (0%)]\tLoss: 4.429003\n",
            "Train Epoch: 3 [6400/20000 (32%)]\tLoss: 4.620408\n",
            "Train Epoch: 3 [12800/20000 (64%)]\tLoss: 4.652662\n",
            "Train Epoch: 3 [19200/20000 (96%)]\tLoss: 4.572064\n",
            "Epoch : 3, Training accuracy : 16.389999389648438 %\n",
            "Epoch : 3, Validation accuracy : 21.520000457763672 %\n",
            "Train Epoch: 4 [0/20000 (0%)]\tLoss: 4.315943\n",
            "Train Epoch: 4 [6400/20000 (32%)]\tLoss: 4.525647\n",
            "Train Epoch: 4 [12800/20000 (64%)]\tLoss: 4.550727\n",
            "Train Epoch: 4 [19200/20000 (96%)]\tLoss: 4.663058\n",
            "Epoch : 4, Training accuracy : 16.75 %\n",
            "Epoch : 4, Validation accuracy : 21.68000030517578 %\n",
            "Train Epoch: 5 [0/20000 (0%)]\tLoss: 4.646218\n",
            "Train Epoch: 5 [6400/20000 (32%)]\tLoss: 4.443109\n",
            "Train Epoch: 5 [12800/20000 (64%)]\tLoss: 4.553217\n",
            "Train Epoch: 5 [19200/20000 (96%)]\tLoss: 4.331200\n",
            "Epoch : 5, Training accuracy : 16.59000015258789 %\n",
            "Epoch : 5, Validation accuracy : 21.799999237060547 %\n",
            "Train Epoch: 6 [0/20000 (0%)]\tLoss: 4.523425\n",
            "Train Epoch: 6 [6400/20000 (32%)]\tLoss: 4.598001\n",
            "Train Epoch: 6 [12800/20000 (64%)]\tLoss: 4.549281\n",
            "Train Epoch: 6 [19200/20000 (96%)]\tLoss: 4.509610\n",
            "Epoch : 6, Training accuracy : 16.44499969482422 %\n",
            "Epoch : 6, Validation accuracy : 21.959999084472656 %\n",
            "Train Epoch: 7 [0/20000 (0%)]\tLoss: 4.466142\n",
            "Train Epoch: 7 [6400/20000 (32%)]\tLoss: 4.699112\n",
            "Train Epoch: 7 [12800/20000 (64%)]\tLoss: 4.581442\n",
            "Train Epoch: 7 [19200/20000 (96%)]\tLoss: 4.578985\n",
            "Epoch : 7, Training accuracy : 16.719999313354492 %\n",
            "Epoch : 7, Validation accuracy : 21.760000228881836 %\n",
            "Train Epoch: 8 [0/20000 (0%)]\tLoss: 4.546360\n",
            "Train Epoch: 8 [6400/20000 (32%)]\tLoss: 4.638419\n",
            "Train Epoch: 8 [12800/20000 (64%)]\tLoss: 4.566610\n",
            "Train Epoch: 8 [19200/20000 (96%)]\tLoss: 4.700437\n",
            "Epoch : 8, Training accuracy : 16.395000457763672 %\n",
            "Epoch : 8, Validation accuracy : 21.360000610351562 %\n",
            "Train Epoch: 9 [0/20000 (0%)]\tLoss: 4.508813\n",
            "Train Epoch: 9 [6400/20000 (32%)]\tLoss: 4.562510\n",
            "Train Epoch: 9 [12800/20000 (64%)]\tLoss: 4.634770\n",
            "Train Epoch: 9 [19200/20000 (96%)]\tLoss: 4.653368\n",
            "Epoch : 9, Training accuracy : 16.600000381469727 %\n",
            "Epoch : 9, Validation accuracy : 21.559999465942383 %\n",
            "Train Epoch: 10 [0/20000 (0%)]\tLoss: 4.603275\n",
            "Train Epoch: 10 [6400/20000 (32%)]\tLoss: 4.465111\n",
            "Train Epoch: 10 [12800/20000 (64%)]\tLoss: 4.542952\n",
            "Train Epoch: 10 [19200/20000 (96%)]\tLoss: 4.587078\n",
            "Epoch : 10, Training accuracy : 16.565000534057617 %\n",
            "Epoch : 10, Validation accuracy : 21.84000015258789 %\n",
            "Train Epoch: 11 [0/20000 (0%)]\tLoss: 4.670962\n",
            "Train Epoch: 11 [6400/20000 (32%)]\tLoss: 4.701519\n",
            "Train Epoch: 11 [12800/20000 (64%)]\tLoss: 4.653458\n",
            "Train Epoch: 11 [19200/20000 (96%)]\tLoss: 4.666229\n",
            "Epoch : 11, Training accuracy : 16.325000762939453 %\n",
            "Epoch : 11, Validation accuracy : 21.399999618530273 %\n",
            "Train Epoch: 12 [0/20000 (0%)]\tLoss: 4.769705\n",
            "Train Epoch: 12 [6400/20000 (32%)]\tLoss: 4.509969\n",
            "Train Epoch: 12 [12800/20000 (64%)]\tLoss: 4.383080\n",
            "Train Epoch: 12 [19200/20000 (96%)]\tLoss: 4.745706\n",
            "Epoch : 12, Training accuracy : 17.315000534057617 %\n",
            "Epoch : 12, Validation accuracy : 21.440000534057617 %\n",
            "Train Epoch: 13 [0/20000 (0%)]\tLoss: 4.823723\n",
            "Train Epoch: 13 [6400/20000 (32%)]\tLoss: 4.572414\n",
            "Train Epoch: 13 [12800/20000 (64%)]\tLoss: 4.549299\n",
            "Train Epoch: 13 [19200/20000 (96%)]\tLoss: 4.637456\n",
            "Epoch : 13, Training accuracy : 17.344999313354492 %\n",
            "Epoch : 13, Validation accuracy : 21.920000076293945 %\n",
            "Train Epoch: 14 [0/20000 (0%)]\tLoss: 4.730386\n",
            "Train Epoch: 14 [6400/20000 (32%)]\tLoss: 4.703563\n",
            "Train Epoch: 14 [12800/20000 (64%)]\tLoss: 4.558053\n",
            "Train Epoch: 14 [19200/20000 (96%)]\tLoss: 4.690740\n",
            "Epoch : 14, Training accuracy : 16.44499969482422 %\n",
            "Epoch : 14, Validation accuracy : 21.68000030517578 %\n",
            "Train Epoch: 15 [0/20000 (0%)]\tLoss: 4.683572\n",
            "Train Epoch: 15 [6400/20000 (32%)]\tLoss: 4.529045\n",
            "Train Epoch: 15 [12800/20000 (64%)]\tLoss: 4.404564\n",
            "Train Epoch: 15 [19200/20000 (96%)]\tLoss: 4.709937\n",
            "Epoch : 15, Training accuracy : 16.985000610351562 %\n",
            "Epoch : 15, Validation accuracy : 21.600000381469727 %\n",
            "Train Epoch: 16 [0/20000 (0%)]\tLoss: 4.590524\n",
            "Train Epoch: 16 [6400/20000 (32%)]\tLoss: 4.622900\n",
            "Train Epoch: 16 [12800/20000 (64%)]\tLoss: 4.528215\n",
            "Train Epoch: 16 [19200/20000 (96%)]\tLoss: 4.485864\n",
            "Epoch : 16, Training accuracy : 16.864999771118164 %\n",
            "Epoch : 16, Validation accuracy : 21.719999313354492 %\n",
            "Train Epoch: 17 [0/20000 (0%)]\tLoss: 4.601091\n",
            "Train Epoch: 17 [6400/20000 (32%)]\tLoss: 4.668570\n",
            "Train Epoch: 17 [12800/20000 (64%)]\tLoss: 4.448326\n",
            "Train Epoch: 17 [19200/20000 (96%)]\tLoss: 4.608969\n",
            "Epoch : 17, Training accuracy : 17.1200008392334 %\n",
            "Epoch : 17, Validation accuracy : 21.520000457763672 %\n",
            "Train Epoch: 18 [0/20000 (0%)]\tLoss: 4.673533\n",
            "Train Epoch: 18 [6400/20000 (32%)]\tLoss: 4.341168\n",
            "Train Epoch: 18 [12800/20000 (64%)]\tLoss: 4.615749\n",
            "Train Epoch: 18 [19200/20000 (96%)]\tLoss: 4.782384\n",
            "Epoch : 18, Training accuracy : 17.209999084472656 %\n",
            "Epoch : 18, Validation accuracy : 21.639999389648438 %\n",
            "Train Epoch: 19 [0/20000 (0%)]\tLoss: 4.709236\n",
            "Train Epoch: 19 [6400/20000 (32%)]\tLoss: 4.587440\n",
            "Train Epoch: 19 [12800/20000 (64%)]\tLoss: 4.304783\n",
            "Train Epoch: 19 [19200/20000 (96%)]\tLoss: 4.428613\n",
            "Epoch : 19, Training accuracy : 17.200000762939453 %\n",
            "Epoch : 19, Validation accuracy : 21.479999542236328 %\n",
            "Train Epoch: 20 [0/20000 (0%)]\tLoss: 4.378668\n",
            "Train Epoch: 20 [6400/20000 (32%)]\tLoss: 4.350699\n",
            "Train Epoch: 20 [12800/20000 (64%)]\tLoss: 4.691383\n",
            "Train Epoch: 20 [19200/20000 (96%)]\tLoss: 4.535470\n",
            "Epoch : 20, Training accuracy : 17.06999969482422 %\n",
            "Epoch : 20, Validation accuracy : 21.799999237060547 %\n",
            "Train Epoch: 21 [0/20000 (0%)]\tLoss: 4.358011\n",
            "Train Epoch: 21 [6400/20000 (32%)]\tLoss: 4.595238\n",
            "Train Epoch: 21 [12800/20000 (64%)]\tLoss: 4.637572\n",
            "Train Epoch: 21 [19200/20000 (96%)]\tLoss: 4.524788\n",
            "Epoch : 21, Training accuracy : 17.68000030517578 %\n",
            "Epoch : 21, Validation accuracy : 21.959999084472656 %\n",
            "Train Epoch: 22 [0/20000 (0%)]\tLoss: 4.563092\n",
            "Train Epoch: 22 [6400/20000 (32%)]\tLoss: 4.402988\n",
            "Train Epoch: 22 [12800/20000 (64%)]\tLoss: 4.580532\n",
            "Train Epoch: 22 [19200/20000 (96%)]\tLoss: 4.450891\n",
            "Epoch : 22, Training accuracy : 17.739999771118164 %\n",
            "Epoch : 22, Validation accuracy : 21.84000015258789 %\n",
            "Train Epoch: 23 [0/20000 (0%)]\tLoss: 4.703259\n",
            "Train Epoch: 23 [6400/20000 (32%)]\tLoss: 4.544362\n",
            "Train Epoch: 23 [12800/20000 (64%)]\tLoss: 4.479561\n",
            "Train Epoch: 23 [19200/20000 (96%)]\tLoss: 4.298977\n",
            "Epoch : 23, Training accuracy : 17.454999923706055 %\n",
            "Epoch : 23, Validation accuracy : 21.68000030517578 %\n",
            "Train Epoch: 24 [0/20000 (0%)]\tLoss: 4.497087\n",
            "Train Epoch: 24 [6400/20000 (32%)]\tLoss: 4.320761\n",
            "Train Epoch: 24 [12800/20000 (64%)]\tLoss: 4.648922\n",
            "Train Epoch: 24 [19200/20000 (96%)]\tLoss: 4.398654\n",
            "Epoch : 24, Training accuracy : 17.6200008392334 %\n",
            "Epoch : 24, Validation accuracy : 21.600000381469727 %\n",
            "Train Epoch: 25 [0/20000 (0%)]\tLoss: 4.651814\n",
            "Train Epoch: 25 [6400/20000 (32%)]\tLoss: 4.441475\n",
            "Train Epoch: 25 [12800/20000 (64%)]\tLoss: 4.529882\n",
            "Train Epoch: 25 [19200/20000 (96%)]\tLoss: 4.447904\n",
            "Epoch : 25, Training accuracy : 16.56999969482422 %\n",
            "Epoch : 25, Validation accuracy : 22.0 %\n",
            "Train Epoch: 26 [0/20000 (0%)]\tLoss: 4.441735\n",
            "Train Epoch: 26 [6400/20000 (32%)]\tLoss: 4.619092\n",
            "Train Epoch: 26 [12800/20000 (64%)]\tLoss: 4.500172\n",
            "Train Epoch: 26 [19200/20000 (96%)]\tLoss: 4.851117\n",
            "Epoch : 26, Training accuracy : 16.3799991607666 %\n",
            "Epoch : 26, Validation accuracy : 21.760000228881836 %\n",
            "Train Epoch: 27 [0/20000 (0%)]\tLoss: 4.461399\n",
            "Train Epoch: 27 [6400/20000 (32%)]\tLoss: 4.498446\n",
            "Train Epoch: 27 [12800/20000 (64%)]\tLoss: 4.566482\n",
            "Train Epoch: 27 [19200/20000 (96%)]\tLoss: 4.581080\n",
            "Epoch : 27, Training accuracy : 16.854999542236328 %\n",
            "Epoch : 27, Validation accuracy : 22.15999984741211 %\n",
            "Train Epoch: 28 [0/20000 (0%)]\tLoss: 4.460272\n",
            "Train Epoch: 28 [6400/20000 (32%)]\tLoss: 4.342677\n",
            "Train Epoch: 28 [12800/20000 (64%)]\tLoss: 4.475753\n",
            "Train Epoch: 28 [19200/20000 (96%)]\tLoss: 4.681514\n",
            "Epoch : 28, Training accuracy : 16.96500015258789 %\n",
            "Epoch : 28, Validation accuracy : 21.760000228881836 %\n",
            "Train Epoch: 29 [0/20000 (0%)]\tLoss: 4.695643\n",
            "Train Epoch: 29 [6400/20000 (32%)]\tLoss: 4.771168\n",
            "Train Epoch: 29 [12800/20000 (64%)]\tLoss: 4.598316\n",
            "Train Epoch: 29 [19200/20000 (96%)]\tLoss: 4.364137\n",
            "Epoch : 29, Training accuracy : 16.809999465942383 %\n",
            "Epoch : 29, Validation accuracy : 22.040000915527344 %\n",
            "Train Epoch: 30 [0/20000 (0%)]\tLoss: 4.615889\n",
            "Train Epoch: 30 [6400/20000 (32%)]\tLoss: 4.595044\n",
            "Train Epoch: 30 [12800/20000 (64%)]\tLoss: 4.543291\n",
            "Train Epoch: 30 [19200/20000 (96%)]\tLoss: 4.635726\n",
            "Epoch : 30, Training accuracy : 16.84000015258789 %\n",
            "Epoch : 30, Validation accuracy : 22.0 %\n",
            "Train Epoch: 31 [0/20000 (0%)]\tLoss: 4.554534\n",
            "Train Epoch: 31 [6400/20000 (32%)]\tLoss: 4.407153\n",
            "Train Epoch: 31 [12800/20000 (64%)]\tLoss: 4.506928\n",
            "Train Epoch: 31 [19200/20000 (96%)]\tLoss: 4.400038\n",
            "Epoch : 31, Training accuracy : 16.56999969482422 %\n",
            "Epoch : 31, Validation accuracy : 21.959999084472656 %\n",
            "Train Epoch: 32 [0/20000 (0%)]\tLoss: 4.592761\n",
            "Train Epoch: 32 [6400/20000 (32%)]\tLoss: 4.366331\n",
            "Train Epoch: 32 [12800/20000 (64%)]\tLoss: 4.444890\n",
            "Train Epoch: 32 [19200/20000 (96%)]\tLoss: 4.506071\n",
            "Epoch : 32, Training accuracy : 16.94499969482422 %\n",
            "Epoch : 32, Validation accuracy : 21.920000076293945 %\n",
            "Train Epoch: 33 [0/20000 (0%)]\tLoss: 4.495405\n",
            "Train Epoch: 33 [6400/20000 (32%)]\tLoss: 4.574284\n",
            "Train Epoch: 33 [12800/20000 (64%)]\tLoss: 4.576760\n",
            "Train Epoch: 33 [19200/20000 (96%)]\tLoss: 4.556441\n",
            "Epoch : 33, Training accuracy : 16.78499984741211 %\n",
            "Epoch : 33, Validation accuracy : 22.1200008392334 %\n",
            "Train Epoch: 34 [0/20000 (0%)]\tLoss: 4.508318\n",
            "Train Epoch: 34 [6400/20000 (32%)]\tLoss: 4.375730\n",
            "Train Epoch: 34 [12800/20000 (64%)]\tLoss: 4.449662\n",
            "Train Epoch: 34 [19200/20000 (96%)]\tLoss: 4.316061\n",
            "Epoch : 34, Training accuracy : 16.795000076293945 %\n",
            "Epoch : 34, Validation accuracy : 21.639999389648438 %\n",
            "Train Epoch: 35 [0/20000 (0%)]\tLoss: 4.599139\n",
            "Train Epoch: 35 [6400/20000 (32%)]\tLoss: 4.516186\n",
            "Train Epoch: 35 [12800/20000 (64%)]\tLoss: 4.583135\n",
            "Train Epoch: 35 [19200/20000 (96%)]\tLoss: 4.770008\n",
            "Epoch : 35, Training accuracy : 16.989999771118164 %\n",
            "Epoch : 35, Validation accuracy : 21.799999237060547 %\n",
            "Train Epoch: 36 [0/20000 (0%)]\tLoss: 4.743991\n",
            "Train Epoch: 36 [6400/20000 (32%)]\tLoss: 4.544978\n",
            "Train Epoch: 36 [12800/20000 (64%)]\tLoss: 4.643247\n",
            "Train Epoch: 36 [19200/20000 (96%)]\tLoss: 4.633472\n",
            "Epoch : 36, Training accuracy : 17.100000381469727 %\n",
            "Epoch : 36, Validation accuracy : 21.920000076293945 %\n",
            "Train Epoch: 37 [0/20000 (0%)]\tLoss: 4.489850\n",
            "Train Epoch: 37 [6400/20000 (32%)]\tLoss: 4.329079\n",
            "Train Epoch: 37 [12800/20000 (64%)]\tLoss: 4.432606\n",
            "Train Epoch: 37 [19200/20000 (96%)]\tLoss: 4.496093\n",
            "Epoch : 37, Training accuracy : 16.709999084472656 %\n",
            "Epoch : 37, Validation accuracy : 21.68000030517578 %\n",
            "Train Epoch: 38 [0/20000 (0%)]\tLoss: 4.465226\n",
            "Train Epoch: 38 [6400/20000 (32%)]\tLoss: 4.455150\n",
            "Train Epoch: 38 [12800/20000 (64%)]\tLoss: 4.641251\n",
            "Train Epoch: 38 [19200/20000 (96%)]\tLoss: 4.594856\n",
            "Epoch : 38, Training accuracy : 17.024999618530273 %\n",
            "Epoch : 38, Validation accuracy : 21.84000015258789 %\n",
            "Train Epoch: 39 [0/20000 (0%)]\tLoss: 4.511249\n",
            "Train Epoch: 39 [6400/20000 (32%)]\tLoss: 4.564805\n",
            "Train Epoch: 39 [12800/20000 (64%)]\tLoss: 4.624809\n",
            "Train Epoch: 39 [19200/20000 (96%)]\tLoss: 4.415669\n",
            "Epoch : 39, Training accuracy : 16.8700008392334 %\n",
            "Epoch : 39, Validation accuracy : 21.760000228881836 %\n",
            "Train Epoch: 40 [0/20000 (0%)]\tLoss: 4.475953\n",
            "Train Epoch: 40 [6400/20000 (32%)]\tLoss: 4.520161\n",
            "Train Epoch: 40 [12800/20000 (64%)]\tLoss: 4.540439\n",
            "Train Epoch: 40 [19200/20000 (96%)]\tLoss: 4.597650\n",
            "Epoch : 40, Training accuracy : 17.010000228881836 %\n",
            "Epoch : 40, Validation accuracy : 21.639999389648438 %\n",
            "Train Epoch: 41 [0/20000 (0%)]\tLoss: 4.464250\n",
            "Train Epoch: 41 [6400/20000 (32%)]\tLoss: 4.484146\n",
            "Train Epoch: 41 [12800/20000 (64%)]\tLoss: 4.402215\n",
            "Train Epoch: 41 [19200/20000 (96%)]\tLoss: 4.561461\n",
            "Epoch : 41, Training accuracy : 17.34000015258789 %\n",
            "Epoch : 41, Validation accuracy : 21.639999389648438 %\n",
            "Train Epoch: 42 [0/20000 (0%)]\tLoss: 4.423894\n",
            "Train Epoch: 42 [6400/20000 (32%)]\tLoss: 4.132144\n",
            "Train Epoch: 42 [12800/20000 (64%)]\tLoss: 4.458210\n",
            "Train Epoch: 42 [19200/20000 (96%)]\tLoss: 4.438354\n",
            "Epoch : 42, Training accuracy : 16.96500015258789 %\n",
            "Epoch : 42, Validation accuracy : 21.639999389648438 %\n",
            "Train Epoch: 43 [0/20000 (0%)]\tLoss: 4.428029\n",
            "Train Epoch: 43 [6400/20000 (32%)]\tLoss: 4.639077\n",
            "Train Epoch: 43 [12800/20000 (64%)]\tLoss: 4.494734\n",
            "Train Epoch: 43 [19200/20000 (96%)]\tLoss: 4.664128\n",
            "Epoch : 43, Training accuracy : 16.940000534057617 %\n",
            "Epoch : 43, Validation accuracy : 22.239999771118164 %\n",
            "Train Epoch: 44 [0/20000 (0%)]\tLoss: 4.560115\n",
            "Train Epoch: 44 [6400/20000 (32%)]\tLoss: 4.715406\n",
            "Train Epoch: 44 [12800/20000 (64%)]\tLoss: 4.615347\n",
            "Train Epoch: 44 [19200/20000 (96%)]\tLoss: 4.494349\n",
            "Epoch : 44, Training accuracy : 17.420000076293945 %\n",
            "Epoch : 44, Validation accuracy : 21.8799991607666 %\n",
            "Train Epoch: 45 [0/20000 (0%)]\tLoss: 4.582324\n",
            "Train Epoch: 45 [6400/20000 (32%)]\tLoss: 4.596712\n",
            "Train Epoch: 45 [12800/20000 (64%)]\tLoss: 4.657809\n",
            "Train Epoch: 45 [19200/20000 (96%)]\tLoss: 4.751677\n",
            "Epoch : 45, Training accuracy : 16.959999084472656 %\n",
            "Epoch : 45, Validation accuracy : 22.15999984741211 %\n",
            "Train Epoch: 46 [0/20000 (0%)]\tLoss: 4.575989\n",
            "Train Epoch: 46 [6400/20000 (32%)]\tLoss: 4.693542\n",
            "Train Epoch: 46 [12800/20000 (64%)]\tLoss: 4.534184\n",
            "Train Epoch: 46 [19200/20000 (96%)]\tLoss: 4.718836\n",
            "Epoch : 46, Training accuracy : 16.674999237060547 %\n",
            "Epoch : 46, Validation accuracy : 22.200000762939453 %\n",
            "Train Epoch: 47 [0/20000 (0%)]\tLoss: 4.259491\n",
            "Train Epoch: 47 [6400/20000 (32%)]\tLoss: 4.586848\n",
            "Train Epoch: 47 [12800/20000 (64%)]\tLoss: 4.647184\n",
            "Train Epoch: 47 [19200/20000 (96%)]\tLoss: 4.636593\n",
            "Epoch : 47, Training accuracy : 17.145000457763672 %\n",
            "Epoch : 47, Validation accuracy : 21.84000015258789 %\n",
            "Train Epoch: 48 [0/20000 (0%)]\tLoss: 4.480586\n",
            "Train Epoch: 48 [6400/20000 (32%)]\tLoss: 4.581843\n",
            "Train Epoch: 48 [12800/20000 (64%)]\tLoss: 4.590327\n",
            "Train Epoch: 48 [19200/20000 (96%)]\tLoss: 4.383086\n",
            "Epoch : 48, Training accuracy : 17.125 %\n",
            "Epoch : 48, Validation accuracy : 21.959999084472656 %\n",
            "Train Epoch: 49 [0/20000 (0%)]\tLoss: 4.613485\n",
            "Train Epoch: 49 [6400/20000 (32%)]\tLoss: 4.515263\n",
            "Train Epoch: 49 [12800/20000 (64%)]\tLoss: 4.557612\n",
            "Train Epoch: 49 [19200/20000 (96%)]\tLoss: 4.560271\n",
            "Epoch : 49, Training accuracy : 17.065000534057617 %\n",
            "Epoch : 49, Validation accuracy : 22.31999969482422 %\n",
            "Train Epoch: 50 [0/20000 (0%)]\tLoss: 4.439762\n",
            "Train Epoch: 50 [6400/20000 (32%)]\tLoss: 4.632214\n",
            "Train Epoch: 50 [12800/20000 (64%)]\tLoss: 4.444890\n",
            "Train Epoch: 50 [19200/20000 (96%)]\tLoss: 4.356011\n",
            "Epoch : 50, Training accuracy : 17.010000228881836 %\n",
            "Epoch : 50, Validation accuracy : 22.239999771118164 %\n",
            "Train Epoch: 51 [0/20000 (0%)]\tLoss: 4.567175\n",
            "Train Epoch: 51 [6400/20000 (32%)]\tLoss: 4.598933\n",
            "Train Epoch: 51 [12800/20000 (64%)]\tLoss: 4.622416\n",
            "Train Epoch: 51 [19200/20000 (96%)]\tLoss: 4.366904\n",
            "Epoch : 51, Training accuracy : 16.895000457763672 %\n",
            "Epoch : 51, Validation accuracy : 22.280000686645508 %\n",
            "Train Epoch: 52 [0/20000 (0%)]\tLoss: 4.418589\n",
            "Train Epoch: 52 [6400/20000 (32%)]\tLoss: 4.577209\n",
            "Train Epoch: 52 [12800/20000 (64%)]\tLoss: 4.869413\n",
            "Train Epoch: 52 [19200/20000 (96%)]\tLoss: 4.346406\n",
            "Epoch : 52, Training accuracy : 16.885000228881836 %\n",
            "Epoch : 52, Validation accuracy : 22.079999923706055 %\n",
            "Train Epoch: 53 [0/20000 (0%)]\tLoss: 4.450936\n",
            "Train Epoch: 53 [6400/20000 (32%)]\tLoss: 4.438724\n",
            "Train Epoch: 53 [12800/20000 (64%)]\tLoss: 4.699607\n",
            "Train Epoch: 53 [19200/20000 (96%)]\tLoss: 4.698744\n",
            "Epoch : 53, Training accuracy : 16.93000030517578 %\n",
            "Epoch : 53, Validation accuracy : 22.280000686645508 %\n",
            "Train Epoch: 54 [0/20000 (0%)]\tLoss: 4.559206\n",
            "Train Epoch: 54 [6400/20000 (32%)]\tLoss: 4.638144\n",
            "Train Epoch: 54 [12800/20000 (64%)]\tLoss: 4.584486\n",
            "Train Epoch: 54 [19200/20000 (96%)]\tLoss: 4.573149\n",
            "Epoch : 54, Training accuracy : 16.739999771118164 %\n",
            "Epoch : 54, Validation accuracy : 22.31999969482422 %\n",
            "Train Epoch: 55 [0/20000 (0%)]\tLoss: 4.556621\n",
            "Train Epoch: 55 [6400/20000 (32%)]\tLoss: 4.293481\n",
            "Train Epoch: 55 [12800/20000 (64%)]\tLoss: 4.614386\n",
            "Train Epoch: 55 [19200/20000 (96%)]\tLoss: 4.516754\n",
            "Epoch : 55, Training accuracy : 17.145000457763672 %\n",
            "Epoch : 55, Validation accuracy : 22.1200008392334 %\n",
            "Train Epoch: 56 [0/20000 (0%)]\tLoss: 4.579196\n",
            "Train Epoch: 56 [6400/20000 (32%)]\tLoss: 4.586885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLqc6a_HB17w",
        "outputId": "eb9a8534-2792-48c9-83a3-e336eb066b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using the Vision Transformer architecture.\n",
            "Succesfully loaded weights\n",
            "successfully parrallelized\n",
            "Using GPU\n",
            "Validation loss : 1.3965706689448296, Validation accuracy : 89.08000183105469 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5455/5455 [03:38<00:00, 25.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfully wrote drive/MyDrive/test_results/vit_vit_large_patch16_224_in21k_fine_tuned_2.csv, you can upload this file to the kaggle competition website\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model_type = \"vit_large_patch16_224_in21k\"\n",
        "tuning_layers = 2\n",
        "model_name = \"vit_\" + model_type + f\"_fine_tuned_{tuning_layers}\"\n",
        "model_path = \"drive/MyDrive/experiment/best_\" + model_name + \".pth\"\n",
        "\n",
        "test(\n",
        "    model_name=model_name,\n",
        "    model_path=model_path,\n",
        "    model_type=model_type,\n",
        "    outfile=f\"drive/MyDrive/test_results/{model_name}.csv\",\n",
        "    data=\"drive/MyDrive/mva_competition\",\n",
        "    batch_size=32,\n",
        "    num_workers=4,\n",
        "    hidden_size=None,\n",
        "    dropout=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_type = \"vit_large_patch16_224_in21k\"\n",
        "tuning_layers = 2\n",
        "model_name = \"vit_\" + model_type + f\"_fine_tuned_{tuning_layers}\"\n",
        "model_path = \"drive/MyDrive/experiment/best_\" + model_name + \".pth\"\n",
        "\n",
        "main(\n",
        "         data_folder=\"drive/MyDrive/mva_competition\",\n",
        "         experiment_folder=\"drive/MyDrive/experiment\",\n",
        "         model_name=model_name,\n",
        "         model_type=model_type,\n",
        "         model_path=model_path,\n",
        "         batch_size=64,\n",
        "         num_workers=4,\n",
        "         momentum=0.5,\n",
        "         epochs=100,\n",
        "         seed=42,\n",
        "         hidden_layers=None,\n",
        "         lr_head=2e-6,\n",
        "         lr_body=2e-6,\n",
        "         saving_frequency=5,\n",
        "         log_interval=50,\n",
        "         tuning_layers=tuning_layers,\n",
        "         fine_tune=True,\n",
        "         optimizer=\"AdamW\",\n",
        "         dropout=0.1\n",
        "     )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "5CRosTwcjXMG",
        "outputId": "51685acd-1ec7-463b-82dd-eadbfa9ad4fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using the Vision Transformer architecture.\n",
            "Succesfully loaded weights\n",
            "successfully parrallelized\n",
            "Using GPU\n",
            "Train Epoch: 1 [0/20000 (0%)]\tLoss: 1.561888\n",
            "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 1.383568\n",
            "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 1.480436\n",
            "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 1.234169\n",
            "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 1.459061\n",
            "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 1.471814\n",
            "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 1.257932\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 74.81 MiB is free. Process 56562 has 39.48 GiB memory in use. Of the allocated memory 38.59 GiB is allocated by PyTorch, and 400.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5116fa408f06>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"drive/MyDrive/experiment/best_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m main(\n\u001b[0m\u001b[1;32m      7\u001b[0m          \u001b[0mdata_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"drive/MyDrive/mva_competition\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m          \u001b[0mexperiment_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"drive/MyDrive/experiment\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/jarry_cv_mva_competition/main.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(data_folder, experiment_folder, model_name, model_path, model_type, batch_size, num_workers, momentum, epochs, seed, lr_head, lr_body, saving_frequency, log_interval, fine_tune, optimizer, hidden_layers, weight_decay, dropout, tuning_layers)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# Validation loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mval_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/jarry_cv_mva_competition/main.py\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(model, val_loader, use_cuda)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;31m# sum up batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mqkv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 74.81 MiB is free. Process 56562 has 39.48 GiB memory in use. Of the allocated memory 38.59 GiB is allocated by PyTorch, and 400.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c7030379477643aba52627f22301e51a",
            "0d56fccd7db84637a8203a7d4fa9d570",
            "1e0c8349271748cdade8ae1a7e7ead2b",
            "a4fe9365c3dc4fb8a52c3d63c480a7c2",
            "9ecd7896d1ef4c75910585e94272cbf5",
            "3e954e61945d40eda4657faf0c961668",
            "623168b0b48f4cfcaf8244ae9dbaf97e",
            "1849590b8dc148ae918118b74ebc561f",
            "2375169808264be8b02103b453cf47fd",
            "0b3144a80b1042dda016d9e01fdf3103",
            "f1e5e01b2ba647c5919c77df3cb665e4"
          ]
        },
        "id": "BRKCdV_zid4q",
        "outputId": "2e2fd3f9-b369-415f-e003-7cc12b81766c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using the Vision Transformer architecture.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name vit_large_patch16_224_in21k to current vit_large_patch16_224.augreg_in21k.\n",
            "  model = create_fn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7030379477643aba52627f22301e51a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.30G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/jarry_cv_mva_competition/model_factory.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(self.model_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfully loaded weights\n",
            "successfully parrallelized\n",
            "Using GPU\n",
            "Train Epoch: 1 [0/20000 (0%)]\tLoss: 2.299547\n",
            "Train Epoch: 1 [1600/20000 (8%)]\tLoss: 2.397828\n",
            "Train Epoch: 1 [3200/20000 (16%)]\tLoss: 1.962160\n",
            "Train Epoch: 1 [4800/20000 (24%)]\tLoss: 1.970581\n",
            "Train Epoch: 1 [6400/20000 (32%)]\tLoss: 1.507411\n",
            "Train Epoch: 1 [8000/20000 (40%)]\tLoss: 2.032376\n",
            "Train Epoch: 1 [9600/20000 (48%)]\tLoss: 1.814116\n",
            "Train Epoch: 1 [11200/20000 (56%)]\tLoss: 2.133243\n",
            "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 2.340969\n",
            "Train Epoch: 1 [14400/20000 (72%)]\tLoss: 2.089848\n",
            "Train Epoch: 1 [16000/20000 (80%)]\tLoss: 2.297624\n",
            "Train Epoch: 1 [17600/20000 (88%)]\tLoss: 1.773965\n",
            "Train Epoch: 1 [19200/20000 (96%)]\tLoss: 2.059276\n",
            "Epoch : 1, Training accuracy : 77.94000244140625 %\n",
            "Epoch : 1, Validation accuracy : 86.91999816894531 %\n",
            "Train Epoch: 2 [0/20000 (0%)]\tLoss: 1.909273\n",
            "Train Epoch: 2 [1600/20000 (8%)]\tLoss: 1.605907\n",
            "Train Epoch: 2 [3200/20000 (16%)]\tLoss: 1.988841\n",
            "Train Epoch: 2 [4800/20000 (24%)]\tLoss: 2.016098\n",
            "Train Epoch: 2 [6400/20000 (32%)]\tLoss: 2.148473\n",
            "Train Epoch: 2 [8000/20000 (40%)]\tLoss: 1.626583\n",
            "Train Epoch: 2 [9600/20000 (48%)]\tLoss: 1.694621\n",
            "Train Epoch: 2 [11200/20000 (56%)]\tLoss: 2.514059\n",
            "Train Epoch: 2 [12800/20000 (64%)]\tLoss: 1.788292\n",
            "Train Epoch: 2 [14400/20000 (72%)]\tLoss: 1.719640\n",
            "Train Epoch: 2 [16000/20000 (80%)]\tLoss: 1.747879\n",
            "Train Epoch: 2 [17600/20000 (88%)]\tLoss: 1.776495\n",
            "Train Epoch: 2 [19200/20000 (96%)]\tLoss: 2.130210\n",
            "Epoch : 2, Training accuracy : 78.43000030517578 %\n",
            "Epoch : 2, Validation accuracy : 87.5199966430664 %\n",
            "Train Epoch: 3 [0/20000 (0%)]\tLoss: 1.391635\n",
            "Train Epoch: 3 [1600/20000 (8%)]\tLoss: 2.020323\n",
            "Train Epoch: 3 [3200/20000 (16%)]\tLoss: 2.777135\n",
            "Train Epoch: 3 [4800/20000 (24%)]\tLoss: 2.141893\n",
            "Train Epoch: 3 [6400/20000 (32%)]\tLoss: 1.754549\n",
            "Train Epoch: 3 [8000/20000 (40%)]\tLoss: 1.908424\n",
            "Train Epoch: 3 [9600/20000 (48%)]\tLoss: 2.642587\n",
            "Train Epoch: 3 [11200/20000 (56%)]\tLoss: 1.323062\n",
            "Train Epoch: 3 [12800/20000 (64%)]\tLoss: 1.612555\n",
            "Train Epoch: 3 [14400/20000 (72%)]\tLoss: 1.722971\n",
            "Train Epoch: 3 [16000/20000 (80%)]\tLoss: 1.890486\n",
            "Train Epoch: 3 [17600/20000 (88%)]\tLoss: 1.346398\n",
            "Train Epoch: 3 [19200/20000 (96%)]\tLoss: 1.726349\n",
            "Epoch : 3, Training accuracy : 78.82499694824219 %\n",
            "Epoch : 3, Validation accuracy : 87.76000213623047 %\n",
            "Train Epoch: 4 [0/20000 (0%)]\tLoss: 2.296477\n",
            "Train Epoch: 4 [1600/20000 (8%)]\tLoss: 1.465223\n",
            "Train Epoch: 4 [3200/20000 (16%)]\tLoss: 1.735826\n",
            "Train Epoch: 4 [4800/20000 (24%)]\tLoss: 2.019500\n",
            "Train Epoch: 4 [6400/20000 (32%)]\tLoss: 1.928158\n",
            "Train Epoch: 4 [8000/20000 (40%)]\tLoss: 2.308001\n",
            "Train Epoch: 4 [9600/20000 (48%)]\tLoss: 2.001803\n",
            "Train Epoch: 4 [11200/20000 (56%)]\tLoss: 1.938504\n",
            "Train Epoch: 4 [12800/20000 (64%)]\tLoss: 2.137566\n",
            "Train Epoch: 4 [14400/20000 (72%)]\tLoss: 2.288004\n",
            "Train Epoch: 4 [16000/20000 (80%)]\tLoss: 1.657814\n",
            "Train Epoch: 4 [17600/20000 (88%)]\tLoss: 1.991363\n",
            "Train Epoch: 4 [19200/20000 (96%)]\tLoss: 1.614638\n",
            "Epoch : 4, Training accuracy : 78.69000244140625 %\n",
            "Epoch : 4, Validation accuracy : 87.95999908447266 %\n",
            "Train Epoch: 5 [0/20000 (0%)]\tLoss: 1.820426\n",
            "Train Epoch: 5 [1600/20000 (8%)]\tLoss: 1.842920\n",
            "Train Epoch: 5 [3200/20000 (16%)]\tLoss: 2.472821\n",
            "Train Epoch: 5 [4800/20000 (24%)]\tLoss: 2.149765\n",
            "Train Epoch: 5 [6400/20000 (32%)]\tLoss: 2.360781\n",
            "Train Epoch: 5 [8000/20000 (40%)]\tLoss: 1.510871\n",
            "Train Epoch: 5 [9600/20000 (48%)]\tLoss: 1.720726\n",
            "Train Epoch: 5 [11200/20000 (56%)]\tLoss: 1.488675\n",
            "Train Epoch: 5 [12800/20000 (64%)]\tLoss: 1.741912\n",
            "Train Epoch: 5 [14400/20000 (72%)]\tLoss: 1.501992\n",
            "Train Epoch: 5 [16000/20000 (80%)]\tLoss: 2.398179\n",
            "Train Epoch: 5 [17600/20000 (88%)]\tLoss: 2.523838\n",
            "Train Epoch: 5 [19200/20000 (96%)]\tLoss: 1.474246\n",
            "Epoch : 5, Training accuracy : 78.66999816894531 %\n",
            "Epoch : 5, Validation accuracy : 87.55999755859375 %\n",
            "Train Epoch: 6 [0/20000 (0%)]\tLoss: 2.116938\n",
            "Train Epoch: 6 [1600/20000 (8%)]\tLoss: 1.971616\n",
            "Train Epoch: 6 [3200/20000 (16%)]\tLoss: 2.319158\n",
            "Train Epoch: 6 [4800/20000 (24%)]\tLoss: 1.609391\n",
            "Train Epoch: 6 [6400/20000 (32%)]\tLoss: 1.742933\n",
            "Train Epoch: 6 [8000/20000 (40%)]\tLoss: 1.482142\n",
            "Train Epoch: 6 [9600/20000 (48%)]\tLoss: 1.586808\n",
            "Train Epoch: 6 [11200/20000 (56%)]\tLoss: 2.242245\n",
            "Train Epoch: 6 [12800/20000 (64%)]\tLoss: 1.873172\n",
            "Train Epoch: 6 [14400/20000 (72%)]\tLoss: 1.710198\n",
            "Train Epoch: 6 [16000/20000 (80%)]\tLoss: 1.876930\n",
            "Train Epoch: 6 [17600/20000 (88%)]\tLoss: 2.167582\n",
            "Train Epoch: 6 [19200/20000 (96%)]\tLoss: 1.704378\n",
            "Epoch : 6, Training accuracy : 78.81500244140625 %\n",
            "Epoch : 6, Validation accuracy : 87.63999938964844 %\n",
            "Train Epoch: 7 [0/20000 (0%)]\tLoss: 1.976505\n",
            "Train Epoch: 7 [1600/20000 (8%)]\tLoss: 1.760094\n",
            "Train Epoch: 7 [3200/20000 (16%)]\tLoss: 1.726604\n",
            "Train Epoch: 7 [4800/20000 (24%)]\tLoss: 1.666331\n",
            "Train Epoch: 7 [6400/20000 (32%)]\tLoss: 2.395741\n",
            "Train Epoch: 7 [8000/20000 (40%)]\tLoss: 2.574852\n",
            "Train Epoch: 7 [9600/20000 (48%)]\tLoss: 1.989683\n",
            "Train Epoch: 7 [11200/20000 (56%)]\tLoss: 2.267170\n",
            "Train Epoch: 7 [12800/20000 (64%)]\tLoss: 1.722614\n",
            "Train Epoch: 7 [14400/20000 (72%)]\tLoss: 1.617205\n",
            "Train Epoch: 7 [16000/20000 (80%)]\tLoss: 1.871258\n",
            "Train Epoch: 7 [17600/20000 (88%)]\tLoss: 1.842093\n",
            "Train Epoch: 7 [19200/20000 (96%)]\tLoss: 2.110844\n",
            "Epoch : 7, Training accuracy : 78.87999725341797 %\n",
            "Epoch : 7, Validation accuracy : 87.5999984741211 %\n",
            "Train Epoch: 8 [0/20000 (0%)]\tLoss: 1.708439\n",
            "Train Epoch: 8 [1600/20000 (8%)]\tLoss: 2.380921\n",
            "Train Epoch: 8 [3200/20000 (16%)]\tLoss: 1.592079\n",
            "Train Epoch: 8 [4800/20000 (24%)]\tLoss: 2.037346\n",
            "Train Epoch: 8 [6400/20000 (32%)]\tLoss: 1.974563\n",
            "Train Epoch: 8 [8000/20000 (40%)]\tLoss: 1.997462\n",
            "Train Epoch: 8 [9600/20000 (48%)]\tLoss: 2.144221\n",
            "Train Epoch: 8 [11200/20000 (56%)]\tLoss: 2.276228\n",
            "Train Epoch: 8 [12800/20000 (64%)]\tLoss: 2.355170\n",
            "Train Epoch: 8 [14400/20000 (72%)]\tLoss: 2.540027\n",
            "Train Epoch: 8 [16000/20000 (80%)]\tLoss: 1.818930\n",
            "Train Epoch: 8 [17600/20000 (88%)]\tLoss: 1.815814\n",
            "Train Epoch: 8 [19200/20000 (96%)]\tLoss: 2.169654\n",
            "Epoch : 8, Training accuracy : 78.4000015258789 %\n",
            "Epoch : 8, Validation accuracy : 88.08000183105469 %\n",
            "Train Epoch: 9 [0/20000 (0%)]\tLoss: 2.040480\n",
            "Train Epoch: 9 [1600/20000 (8%)]\tLoss: 1.982897\n",
            "Train Epoch: 9 [3200/20000 (16%)]\tLoss: 2.229687\n",
            "Train Epoch: 9 [4800/20000 (24%)]\tLoss: 2.254082\n",
            "Train Epoch: 9 [6400/20000 (32%)]\tLoss: 2.049178\n",
            "Train Epoch: 9 [8000/20000 (40%)]\tLoss: 1.728986\n",
            "Train Epoch: 9 [9600/20000 (48%)]\tLoss: 2.363342\n",
            "Train Epoch: 9 [11200/20000 (56%)]\tLoss: 1.930374\n",
            "Train Epoch: 9 [12800/20000 (64%)]\tLoss: 1.905329\n",
            "Train Epoch: 9 [14400/20000 (72%)]\tLoss: 2.255329\n",
            "Train Epoch: 9 [16000/20000 (80%)]\tLoss: 2.068698\n",
            "Train Epoch: 9 [17600/20000 (88%)]\tLoss: 1.728709\n",
            "Train Epoch: 9 [19200/20000 (96%)]\tLoss: 1.532939\n",
            "Epoch : 9, Training accuracy : 79.20500183105469 %\n",
            "Epoch : 9, Validation accuracy : 87.91999816894531 %\n",
            "Train Epoch: 10 [0/20000 (0%)]\tLoss: 1.721617\n",
            "Train Epoch: 10 [1600/20000 (8%)]\tLoss: 2.479118\n",
            "Train Epoch: 10 [3200/20000 (16%)]\tLoss: 1.874389\n",
            "Train Epoch: 10 [4800/20000 (24%)]\tLoss: 1.967737\n",
            "Train Epoch: 10 [6400/20000 (32%)]\tLoss: 1.984719\n",
            "Train Epoch: 10 [8000/20000 (40%)]\tLoss: 1.975941\n",
            "Train Epoch: 10 [9600/20000 (48%)]\tLoss: 1.446803\n",
            "Train Epoch: 10 [11200/20000 (56%)]\tLoss: 2.095678\n",
            "Train Epoch: 10 [12800/20000 (64%)]\tLoss: 2.375216\n",
            "Train Epoch: 10 [14400/20000 (72%)]\tLoss: 1.964869\n",
            "Train Epoch: 10 [16000/20000 (80%)]\tLoss: 1.758080\n",
            "Train Epoch: 10 [17600/20000 (88%)]\tLoss: 1.883206\n",
            "Train Epoch: 10 [19200/20000 (96%)]\tLoss: 2.269685\n",
            "Epoch : 10, Training accuracy : 79.25499725341797 %\n",
            "Epoch : 10, Validation accuracy : 88.63999938964844 %\n",
            "Train Epoch: 11 [0/20000 (0%)]\tLoss: 1.453974\n",
            "Train Epoch: 11 [1600/20000 (8%)]\tLoss: 2.252712\n",
            "Train Epoch: 11 [3200/20000 (16%)]\tLoss: 2.165220\n",
            "Train Epoch: 11 [4800/20000 (24%)]\tLoss: 2.022051\n",
            "Train Epoch: 11 [6400/20000 (32%)]\tLoss: 1.599464\n",
            "Train Epoch: 11 [8000/20000 (40%)]\tLoss: 2.159700\n",
            "Train Epoch: 11 [9600/20000 (48%)]\tLoss: 1.961300\n",
            "Train Epoch: 11 [11200/20000 (56%)]\tLoss: 1.738604\n",
            "Train Epoch: 11 [12800/20000 (64%)]\tLoss: 2.541339\n",
            "Train Epoch: 11 [14400/20000 (72%)]\tLoss: 1.942253\n",
            "Train Epoch: 11 [16000/20000 (80%)]\tLoss: 1.574584\n",
            "Train Epoch: 11 [17600/20000 (88%)]\tLoss: 2.355830\n",
            "Train Epoch: 11 [19200/20000 (96%)]\tLoss: 1.377175\n",
            "Epoch : 11, Training accuracy : 79.16000366210938 %\n",
            "Epoch : 11, Validation accuracy : 87.91999816894531 %\n",
            "Train Epoch: 12 [0/20000 (0%)]\tLoss: 2.124474\n",
            "Train Epoch: 12 [1600/20000 (8%)]\tLoss: 1.557378\n",
            "Train Epoch: 12 [3200/20000 (16%)]\tLoss: 1.888812\n",
            "Train Epoch: 12 [4800/20000 (24%)]\tLoss: 1.958568\n",
            "Train Epoch: 12 [6400/20000 (32%)]\tLoss: 2.084395\n",
            "Train Epoch: 12 [8000/20000 (40%)]\tLoss: 1.609419\n",
            "Train Epoch: 12 [9600/20000 (48%)]\tLoss: 1.845368\n",
            "Train Epoch: 12 [11200/20000 (56%)]\tLoss: 1.875938\n",
            "Train Epoch: 12 [12800/20000 (64%)]\tLoss: 2.100866\n",
            "Train Epoch: 12 [14400/20000 (72%)]\tLoss: 2.250876\n",
            "Train Epoch: 12 [16000/20000 (80%)]\tLoss: 1.595407\n",
            "Train Epoch: 12 [17600/20000 (88%)]\tLoss: 2.238635\n",
            "Train Epoch: 12 [19200/20000 (96%)]\tLoss: 1.793051\n",
            "Epoch : 12, Training accuracy : 78.6050033569336 %\n",
            "Epoch : 12, Validation accuracy : 88.55999755859375 %\n",
            "Train Epoch: 13 [0/20000 (0%)]\tLoss: 1.727756\n",
            "Train Epoch: 13 [1600/20000 (8%)]\tLoss: 1.700508\n",
            "Train Epoch: 13 [3200/20000 (16%)]\tLoss: 2.002871\n",
            "Train Epoch: 13 [4800/20000 (24%)]\tLoss: 1.800251\n",
            "Train Epoch: 13 [6400/20000 (32%)]\tLoss: 2.491832\n",
            "Train Epoch: 13 [8000/20000 (40%)]\tLoss: 1.916722\n",
            "Train Epoch: 13 [9600/20000 (48%)]\tLoss: 2.504687\n",
            "Train Epoch: 13 [11200/20000 (56%)]\tLoss: 2.231097\n",
            "Train Epoch: 13 [12800/20000 (64%)]\tLoss: 1.593000\n",
            "Train Epoch: 13 [14400/20000 (72%)]\tLoss: 2.081983\n",
            "Train Epoch: 13 [16000/20000 (80%)]\tLoss: 2.248349\n",
            "Train Epoch: 13 [17600/20000 (88%)]\tLoss: 1.949976\n",
            "Train Epoch: 13 [19200/20000 (96%)]\tLoss: 2.015992\n",
            "Epoch : 13, Training accuracy : 78.69999694824219 %\n",
            "Epoch : 13, Validation accuracy : 88.4800033569336 %\n",
            "Train Epoch: 14 [0/20000 (0%)]\tLoss: 1.443821\n",
            "Train Epoch: 14 [1600/20000 (8%)]\tLoss: 1.815769\n",
            "Train Epoch: 14 [3200/20000 (16%)]\tLoss: 2.243154\n",
            "Train Epoch: 14 [4800/20000 (24%)]\tLoss: 1.733084\n",
            "Train Epoch: 14 [6400/20000 (32%)]\tLoss: 1.987142\n",
            "Train Epoch: 14 [8000/20000 (40%)]\tLoss: 2.223924\n",
            "Train Epoch: 14 [9600/20000 (48%)]\tLoss: 1.837966\n",
            "Train Epoch: 14 [11200/20000 (56%)]\tLoss: 1.848880\n",
            "Train Epoch: 14 [12800/20000 (64%)]\tLoss: 1.755481\n",
            "Train Epoch: 14 [14400/20000 (72%)]\tLoss: 2.242063\n",
            "Train Epoch: 14 [16000/20000 (80%)]\tLoss: 1.944184\n",
            "Train Epoch: 14 [17600/20000 (88%)]\tLoss: 2.627561\n",
            "Train Epoch: 14 [19200/20000 (96%)]\tLoss: 1.943353\n",
            "Epoch : 14, Training accuracy : 78.81500244140625 %\n",
            "Epoch : 14, Validation accuracy : 88.4000015258789 %\n",
            "Train Epoch: 15 [0/20000 (0%)]\tLoss: 2.464480\n",
            "Train Epoch: 15 [1600/20000 (8%)]\tLoss: 1.716392\n",
            "Train Epoch: 15 [3200/20000 (16%)]\tLoss: 2.502001\n",
            "Train Epoch: 15 [4800/20000 (24%)]\tLoss: 2.027792\n",
            "Train Epoch: 15 [6400/20000 (32%)]\tLoss: 1.968738\n",
            "Train Epoch: 15 [8000/20000 (40%)]\tLoss: 1.442168\n",
            "Train Epoch: 15 [9600/20000 (48%)]\tLoss: 1.786864\n",
            "Train Epoch: 15 [11200/20000 (56%)]\tLoss: 1.456766\n",
            "Train Epoch: 15 [12800/20000 (64%)]\tLoss: 2.194744\n",
            "Train Epoch: 15 [14400/20000 (72%)]\tLoss: 2.027944\n",
            "Train Epoch: 15 [16000/20000 (80%)]\tLoss: 1.710099\n",
            "Train Epoch: 15 [17600/20000 (88%)]\tLoss: 1.712613\n",
            "Train Epoch: 15 [19200/20000 (96%)]\tLoss: 1.708771\n",
            "Epoch : 15, Training accuracy : 78.75 %\n",
            "Epoch : 15, Validation accuracy : 88.44000244140625 %\n",
            "Train Epoch: 16 [0/20000 (0%)]\tLoss: 1.724577\n",
            "Train Epoch: 16 [1600/20000 (8%)]\tLoss: 2.087152\n",
            "Train Epoch: 16 [3200/20000 (16%)]\tLoss: 1.675440\n",
            "Train Epoch: 16 [4800/20000 (24%)]\tLoss: 2.074808\n",
            "Train Epoch: 16 [6400/20000 (32%)]\tLoss: 2.267124\n",
            "Train Epoch: 16 [8000/20000 (40%)]\tLoss: 1.953410\n",
            "Train Epoch: 16 [9600/20000 (48%)]\tLoss: 1.837160\n",
            "Train Epoch: 16 [11200/20000 (56%)]\tLoss: 2.242280\n",
            "Train Epoch: 16 [12800/20000 (64%)]\tLoss: 2.392894\n",
            "Train Epoch: 16 [14400/20000 (72%)]\tLoss: 1.835609\n",
            "Train Epoch: 16 [16000/20000 (80%)]\tLoss: 1.696759\n",
            "Train Epoch: 16 [17600/20000 (88%)]\tLoss: 2.080467\n",
            "Train Epoch: 16 [19200/20000 (96%)]\tLoss: 1.871097\n",
            "Epoch : 16, Training accuracy : 78.7750015258789 %\n",
            "Epoch : 16, Validation accuracy : 88.4000015258789 %\n",
            "Train Epoch: 17 [0/20000 (0%)]\tLoss: 1.716671\n",
            "Train Epoch: 17 [1600/20000 (8%)]\tLoss: 2.096658\n",
            "Train Epoch: 17 [3200/20000 (16%)]\tLoss: 2.017640\n",
            "Train Epoch: 17 [4800/20000 (24%)]\tLoss: 1.629012\n",
            "Train Epoch: 17 [6400/20000 (32%)]\tLoss: 1.770745\n",
            "Train Epoch: 17 [8000/20000 (40%)]\tLoss: 1.597951\n",
            "Train Epoch: 17 [9600/20000 (48%)]\tLoss: 1.962960\n",
            "Train Epoch: 17 [11200/20000 (56%)]\tLoss: 2.249000\n",
            "Train Epoch: 17 [12800/20000 (64%)]\tLoss: 1.447493\n",
            "Train Epoch: 17 [14400/20000 (72%)]\tLoss: 1.902147\n",
            "Train Epoch: 17 [16000/20000 (80%)]\tLoss: 2.091485\n",
            "Train Epoch: 17 [17600/20000 (88%)]\tLoss: 1.962296\n",
            "Train Epoch: 17 [19200/20000 (96%)]\tLoss: 1.712512\n",
            "Epoch : 17, Training accuracy : 78.43000030517578 %\n",
            "Epoch : 17, Validation accuracy : 88.04000091552734 %\n",
            "Train Epoch: 18 [0/20000 (0%)]\tLoss: 2.344601\n",
            "Train Epoch: 18 [1600/20000 (8%)]\tLoss: 2.008988\n",
            "Train Epoch: 18 [3200/20000 (16%)]\tLoss: 1.701998\n",
            "Train Epoch: 18 [4800/20000 (24%)]\tLoss: 2.584014\n",
            "Train Epoch: 18 [6400/20000 (32%)]\tLoss: 1.337318\n",
            "Train Epoch: 18 [8000/20000 (40%)]\tLoss: 1.781102\n",
            "Train Epoch: 18 [9600/20000 (48%)]\tLoss: 2.810941\n",
            "Train Epoch: 18 [11200/20000 (56%)]\tLoss: 1.874344\n",
            "Train Epoch: 18 [12800/20000 (64%)]\tLoss: 1.596651\n",
            "Train Epoch: 18 [14400/20000 (72%)]\tLoss: 2.269346\n",
            "Train Epoch: 18 [16000/20000 (80%)]\tLoss: 1.836221\n",
            "Train Epoch: 18 [17600/20000 (88%)]\tLoss: 2.242181\n",
            "Train Epoch: 18 [19200/20000 (96%)]\tLoss: 2.211910\n",
            "Epoch : 18, Training accuracy : 78.95999908447266 %\n",
            "Epoch : 18, Validation accuracy : 88.04000091552734 %\n",
            "Train Epoch: 19 [0/20000 (0%)]\tLoss: 1.555535\n",
            "Train Epoch: 19 [1600/20000 (8%)]\tLoss: 2.504107\n",
            "Train Epoch: 19 [3200/20000 (16%)]\tLoss: 1.964290\n",
            "Train Epoch: 19 [4800/20000 (24%)]\tLoss: 1.810611\n",
            "Train Epoch: 19 [6400/20000 (32%)]\tLoss: 1.616992\n",
            "Train Epoch: 19 [8000/20000 (40%)]\tLoss: 1.964148\n",
            "Train Epoch: 19 [9600/20000 (48%)]\tLoss: 1.703521\n",
            "Train Epoch: 19 [11200/20000 (56%)]\tLoss: 1.961293\n",
            "Train Epoch: 19 [12800/20000 (64%)]\tLoss: 2.406375\n",
            "Train Epoch: 19 [14400/20000 (72%)]\tLoss: 2.067590\n",
            "Train Epoch: 19 [16000/20000 (80%)]\tLoss: 2.335714\n",
            "Train Epoch: 19 [17600/20000 (88%)]\tLoss: 1.839291\n",
            "Train Epoch: 19 [19200/20000 (96%)]\tLoss: 2.210429\n",
            "Epoch : 19, Training accuracy : 78.84500122070312 %\n",
            "Epoch : 19, Validation accuracy : 88.55999755859375 %\n",
            "Train Epoch: 20 [0/20000 (0%)]\tLoss: 1.704033\n",
            "Train Epoch: 20 [1600/20000 (8%)]\tLoss: 1.470896\n",
            "Train Epoch: 20 [3200/20000 (16%)]\tLoss: 1.973593\n",
            "Train Epoch: 20 [4800/20000 (24%)]\tLoss: 2.023019\n",
            "Train Epoch: 20 [6400/20000 (32%)]\tLoss: 2.123999\n",
            "Train Epoch: 20 [8000/20000 (40%)]\tLoss: 1.948019\n",
            "Train Epoch: 20 [9600/20000 (48%)]\tLoss: 1.976629\n",
            "Train Epoch: 20 [11200/20000 (56%)]\tLoss: 1.311837\n",
            "Train Epoch: 20 [12800/20000 (64%)]\tLoss: 1.532608\n",
            "Train Epoch: 20 [14400/20000 (72%)]\tLoss: 1.714031\n",
            "Train Epoch: 20 [16000/20000 (80%)]\tLoss: 1.480543\n",
            "Train Epoch: 20 [17600/20000 (88%)]\tLoss: 2.158330\n",
            "Train Epoch: 20 [19200/20000 (96%)]\tLoss: 2.238500\n",
            "Epoch : 20, Training accuracy : 78.9000015258789 %\n",
            "Epoch : 20, Validation accuracy : 88.23999786376953 %\n",
            "Train Epoch: 21 [0/20000 (0%)]\tLoss: 1.861773\n",
            "Train Epoch: 21 [1600/20000 (8%)]\tLoss: 1.958842\n",
            "Train Epoch: 21 [3200/20000 (16%)]\tLoss: 1.691624\n",
            "Train Epoch: 21 [4800/20000 (24%)]\tLoss: 1.972678\n",
            "Train Epoch: 21 [6400/20000 (32%)]\tLoss: 1.975351\n",
            "Train Epoch: 21 [8000/20000 (40%)]\tLoss: 1.948479\n",
            "Train Epoch: 21 [9600/20000 (48%)]\tLoss: 1.882886\n",
            "Train Epoch: 21 [11200/20000 (56%)]\tLoss: 2.549909\n",
            "Train Epoch: 21 [12800/20000 (64%)]\tLoss: 1.711035\n",
            "Train Epoch: 21 [14400/20000 (72%)]\tLoss: 2.015117\n",
            "Train Epoch: 21 [16000/20000 (80%)]\tLoss: 1.716402\n",
            "Train Epoch: 21 [17600/20000 (88%)]\tLoss: 1.702543\n",
            "Train Epoch: 21 [19200/20000 (96%)]\tLoss: 2.343124\n",
            "Epoch : 21, Training accuracy : 78.43499755859375 %\n",
            "Epoch : 21, Validation accuracy : 88.5199966430664 %\n",
            "Train Epoch: 22 [0/20000 (0%)]\tLoss: 1.959936\n",
            "Train Epoch: 22 [1600/20000 (8%)]\tLoss: 1.670882\n",
            "Train Epoch: 22 [3200/20000 (16%)]\tLoss: 2.078227\n",
            "Train Epoch: 22 [4800/20000 (24%)]\tLoss: 1.876648\n",
            "Train Epoch: 22 [6400/20000 (32%)]\tLoss: 1.983264\n",
            "Train Epoch: 22 [8000/20000 (40%)]\tLoss: 2.374295\n",
            "Train Epoch: 22 [9600/20000 (48%)]\tLoss: 1.681822\n",
            "Train Epoch: 22 [11200/20000 (56%)]\tLoss: 1.601309\n",
            "Train Epoch: 22 [12800/20000 (64%)]\tLoss: 1.983874\n",
            "Train Epoch: 22 [14400/20000 (72%)]\tLoss: 1.709992\n",
            "Train Epoch: 22 [16000/20000 (80%)]\tLoss: 1.364593\n",
            "Train Epoch: 22 [17600/20000 (88%)]\tLoss: 2.517949\n",
            "Train Epoch: 22 [19200/20000 (96%)]\tLoss: 2.236832\n",
            "Epoch : 22, Training accuracy : 78.83000183105469 %\n",
            "Epoch : 22, Validation accuracy : 88.4000015258789 %\n",
            "Train Epoch: 23 [0/20000 (0%)]\tLoss: 1.696441\n",
            "Train Epoch: 23 [1600/20000 (8%)]\tLoss: 1.719190\n",
            "Train Epoch: 23 [3200/20000 (16%)]\tLoss: 2.200420\n",
            "Train Epoch: 23 [4800/20000 (24%)]\tLoss: 1.934234\n",
            "Train Epoch: 23 [6400/20000 (32%)]\tLoss: 2.080774\n",
            "Train Epoch: 23 [8000/20000 (40%)]\tLoss: 2.217855\n",
            "Train Epoch: 23 [9600/20000 (48%)]\tLoss: 2.305979\n",
            "Train Epoch: 23 [11200/20000 (56%)]\tLoss: 1.569333\n",
            "Train Epoch: 23 [12800/20000 (64%)]\tLoss: 1.711987\n",
            "Train Epoch: 23 [14400/20000 (72%)]\tLoss: 1.824621\n",
            "Train Epoch: 23 [16000/20000 (80%)]\tLoss: 1.841443\n",
            "Train Epoch: 23 [17600/20000 (88%)]\tLoss: 1.606981\n",
            "Train Epoch: 23 [19200/20000 (96%)]\tLoss: 1.682822\n",
            "Epoch : 23, Training accuracy : 78.88500213623047 %\n",
            "Epoch : 23, Validation accuracy : 88.68000030517578 %\n",
            "Train Epoch: 24 [0/20000 (0%)]\tLoss: 2.142885\n",
            "Train Epoch: 24 [1600/20000 (8%)]\tLoss: 1.564483\n",
            "Train Epoch: 24 [3200/20000 (16%)]\tLoss: 2.210160\n",
            "Train Epoch: 24 [4800/20000 (24%)]\tLoss: 2.260245\n",
            "Train Epoch: 24 [6400/20000 (32%)]\tLoss: 2.281341\n",
            "Train Epoch: 24 [8000/20000 (40%)]\tLoss: 1.832134\n",
            "Train Epoch: 24 [9600/20000 (48%)]\tLoss: 1.716044\n",
            "Train Epoch: 24 [11200/20000 (56%)]\tLoss: 2.298342\n",
            "Train Epoch: 24 [12800/20000 (64%)]\tLoss: 2.512150\n",
            "Train Epoch: 24 [14400/20000 (72%)]\tLoss: 1.865836\n",
            "Train Epoch: 24 [16000/20000 (80%)]\tLoss: 1.946387\n",
            "Train Epoch: 24 [17600/20000 (88%)]\tLoss: 2.196734\n",
            "Train Epoch: 24 [19200/20000 (96%)]\tLoss: 1.948293\n",
            "Epoch : 24, Training accuracy : 78.71499633789062 %\n",
            "Epoch : 24, Validation accuracy : 89.04000091552734 %\n",
            "Train Epoch: 25 [0/20000 (0%)]\tLoss: 1.687362\n",
            "Train Epoch: 25 [1600/20000 (8%)]\tLoss: 1.651702\n",
            "Train Epoch: 25 [3200/20000 (16%)]\tLoss: 2.315651\n",
            "Train Epoch: 25 [4800/20000 (24%)]\tLoss: 2.148060\n",
            "Train Epoch: 25 [6400/20000 (32%)]\tLoss: 1.839292\n",
            "Train Epoch: 25 [8000/20000 (40%)]\tLoss: 2.775099\n",
            "Train Epoch: 25 [9600/20000 (48%)]\tLoss: 2.297320\n",
            "Train Epoch: 25 [11200/20000 (56%)]\tLoss: 1.487776\n",
            "Train Epoch: 25 [12800/20000 (64%)]\tLoss: 1.695871\n",
            "Train Epoch: 25 [14400/20000 (72%)]\tLoss: 1.672430\n",
            "Train Epoch: 25 [16000/20000 (80%)]\tLoss: 1.593317\n",
            "Train Epoch: 25 [17600/20000 (88%)]\tLoss: 1.460295\n",
            "Train Epoch: 25 [19200/20000 (96%)]\tLoss: 1.998728\n",
            "Epoch : 25, Training accuracy : 79.04000091552734 %\n",
            "Epoch : 25, Validation accuracy : 88.44000244140625 %\n",
            "Train Epoch: 26 [0/20000 (0%)]\tLoss: 2.268931\n",
            "Train Epoch: 26 [1600/20000 (8%)]\tLoss: 1.949560\n",
            "Train Epoch: 26 [3200/20000 (16%)]\tLoss: 1.855380\n",
            "Train Epoch: 26 [4800/20000 (24%)]\tLoss: 1.430032\n",
            "Train Epoch: 26 [6400/20000 (32%)]\tLoss: 1.854919\n",
            "Train Epoch: 26 [8000/20000 (40%)]\tLoss: 2.181354\n",
            "Train Epoch: 26 [9600/20000 (48%)]\tLoss: 1.960008\n",
            "Train Epoch: 26 [11200/20000 (56%)]\tLoss: 2.801403\n",
            "Train Epoch: 26 [12800/20000 (64%)]\tLoss: 2.125418\n",
            "Train Epoch: 26 [14400/20000 (72%)]\tLoss: 1.982877\n",
            "Train Epoch: 26 [16000/20000 (80%)]\tLoss: 1.679326\n",
            "Train Epoch: 26 [17600/20000 (88%)]\tLoss: 1.454011\n",
            "Train Epoch: 26 [19200/20000 (96%)]\tLoss: 1.955524\n",
            "Epoch : 26, Training accuracy : 78.29000091552734 %\n",
            "Epoch : 26, Validation accuracy : 88.23999786376953 %\n",
            "Train Epoch: 27 [0/20000 (0%)]\tLoss: 1.806850\n",
            "Train Epoch: 27 [1600/20000 (8%)]\tLoss: 1.976790\n",
            "Train Epoch: 27 [3200/20000 (16%)]\tLoss: 2.119353\n",
            "Train Epoch: 27 [4800/20000 (24%)]\tLoss: 2.039591\n",
            "Train Epoch: 27 [6400/20000 (32%)]\tLoss: 1.692598\n",
            "Train Epoch: 27 [8000/20000 (40%)]\tLoss: 2.375197\n",
            "Train Epoch: 27 [9600/20000 (48%)]\tLoss: 1.960857\n",
            "Train Epoch: 27 [11200/20000 (56%)]\tLoss: 2.338188\n",
            "Train Epoch: 27 [12800/20000 (64%)]\tLoss: 1.829008\n",
            "Train Epoch: 27 [14400/20000 (72%)]\tLoss: 2.085269\n",
            "Train Epoch: 27 [16000/20000 (80%)]\tLoss: 1.577554\n",
            "Train Epoch: 27 [17600/20000 (88%)]\tLoss: 2.315505\n",
            "Train Epoch: 27 [19200/20000 (96%)]\tLoss: 1.656908\n",
            "Epoch : 27, Training accuracy : 78.54000091552734 %\n",
            "Epoch : 27, Validation accuracy : 88.31999969482422 %\n",
            "Train Epoch: 28 [0/20000 (0%)]\tLoss: 1.562794\n",
            "Train Epoch: 28 [1600/20000 (8%)]\tLoss: 1.805043\n",
            "Train Epoch: 28 [3200/20000 (16%)]\tLoss: 2.005252\n",
            "Train Epoch: 28 [4800/20000 (24%)]\tLoss: 1.718500\n",
            "Train Epoch: 28 [6400/20000 (32%)]\tLoss: 1.948203\n",
            "Train Epoch: 28 [8000/20000 (40%)]\tLoss: 1.690566\n",
            "Train Epoch: 28 [9600/20000 (48%)]\tLoss: 1.938893\n",
            "Train Epoch: 28 [11200/20000 (56%)]\tLoss: 1.462526\n",
            "Train Epoch: 28 [12800/20000 (64%)]\tLoss: 2.073496\n",
            "Train Epoch: 28 [14400/20000 (72%)]\tLoss: 1.949279\n",
            "Train Epoch: 28 [16000/20000 (80%)]\tLoss: 1.728381\n",
            "Train Epoch: 28 [17600/20000 (88%)]\tLoss: 2.194767\n",
            "Train Epoch: 28 [19200/20000 (96%)]\tLoss: 2.176382\n",
            "Epoch : 28, Training accuracy : 78.56500244140625 %\n",
            "Epoch : 28, Validation accuracy : 88.31999969482422 %\n",
            "Train Epoch: 29 [0/20000 (0%)]\tLoss: 2.912207\n",
            "Train Epoch: 29 [1600/20000 (8%)]\tLoss: 1.821731\n",
            "Train Epoch: 29 [3200/20000 (16%)]\tLoss: 1.715482\n",
            "Train Epoch: 29 [4800/20000 (24%)]\tLoss: 2.081301\n",
            "Train Epoch: 29 [6400/20000 (32%)]\tLoss: 1.675463\n",
            "Train Epoch: 29 [8000/20000 (40%)]\tLoss: 1.943494\n",
            "Train Epoch: 29 [9600/20000 (48%)]\tLoss: 1.609706\n",
            "Train Epoch: 29 [11200/20000 (56%)]\tLoss: 1.955174\n",
            "Train Epoch: 29 [12800/20000 (64%)]\tLoss: 1.675000\n",
            "Train Epoch: 29 [14400/20000 (72%)]\tLoss: 1.681244\n",
            "Train Epoch: 29 [16000/20000 (80%)]\tLoss: 1.813627\n",
            "Train Epoch: 29 [17600/20000 (88%)]\tLoss: 1.854967\n",
            "Train Epoch: 29 [19200/20000 (96%)]\tLoss: 1.981122\n",
            "Epoch : 29, Training accuracy : 79.33000183105469 %\n",
            "Epoch : 29, Validation accuracy : 88.55999755859375 %\n",
            "Train Epoch: 30 [0/20000 (0%)]\tLoss: 2.081848\n",
            "Train Epoch: 30 [1600/20000 (8%)]\tLoss: 1.813150\n",
            "Train Epoch: 30 [3200/20000 (16%)]\tLoss: 2.180377\n",
            "Train Epoch: 30 [4800/20000 (24%)]\tLoss: 2.212063\n",
            "Train Epoch: 30 [6400/20000 (32%)]\tLoss: 2.068895\n",
            "Train Epoch: 30 [8000/20000 (40%)]\tLoss: 1.683399\n",
            "Train Epoch: 30 [9600/20000 (48%)]\tLoss: 1.412305\n",
            "Train Epoch: 30 [11200/20000 (56%)]\tLoss: 2.866334\n",
            "Train Epoch: 30 [12800/20000 (64%)]\tLoss: 1.825260\n",
            "Train Epoch: 30 [14400/20000 (72%)]\tLoss: 2.265860\n",
            "Train Epoch: 30 [16000/20000 (80%)]\tLoss: 2.154647\n",
            "Train Epoch: 30 [17600/20000 (88%)]\tLoss: 1.698298\n",
            "Train Epoch: 30 [19200/20000 (96%)]\tLoss: 1.947149\n",
            "Epoch : 30, Training accuracy : 78.91999816894531 %\n",
            "Epoch : 30, Validation accuracy : 88.08000183105469 %\n",
            "Train Epoch: 31 [0/20000 (0%)]\tLoss: 2.392190\n",
            "Train Epoch: 31 [1600/20000 (8%)]\tLoss: 1.534000\n",
            "Train Epoch: 31 [3200/20000 (16%)]\tLoss: 1.430695\n",
            "Train Epoch: 31 [4800/20000 (24%)]\tLoss: 1.760822\n",
            "Train Epoch: 31 [6400/20000 (32%)]\tLoss: 2.532608\n",
            "Train Epoch: 31 [8000/20000 (40%)]\tLoss: 2.107611\n",
            "Train Epoch: 31 [9600/20000 (48%)]\tLoss: 1.690694\n",
            "Train Epoch: 31 [11200/20000 (56%)]\tLoss: 2.085005\n",
            "Train Epoch: 31 [12800/20000 (64%)]\tLoss: 2.164275\n",
            "Train Epoch: 31 [14400/20000 (72%)]\tLoss: 1.582946\n",
            "Train Epoch: 31 [16000/20000 (80%)]\tLoss: 1.457153\n",
            "Train Epoch: 31 [17600/20000 (88%)]\tLoss: 1.838102\n",
            "Train Epoch: 31 [19200/20000 (96%)]\tLoss: 2.067101\n",
            "Epoch : 31, Training accuracy : 79.15499877929688 %\n",
            "Epoch : 31, Validation accuracy : 88.08000183105469 %\n",
            "Train Epoch: 32 [0/20000 (0%)]\tLoss: 1.719757\n",
            "Train Epoch: 32 [1600/20000 (8%)]\tLoss: 1.986438\n",
            "Train Epoch: 32 [3200/20000 (16%)]\tLoss: 1.948556\n",
            "Train Epoch: 32 [4800/20000 (24%)]\tLoss: 2.067204\n",
            "Train Epoch: 32 [6400/20000 (32%)]\tLoss: 1.438191\n",
            "Train Epoch: 32 [8000/20000 (40%)]\tLoss: 1.859907\n",
            "Train Epoch: 32 [9600/20000 (48%)]\tLoss: 1.426929\n",
            "Train Epoch: 32 [11200/20000 (56%)]\tLoss: 1.708224\n",
            "Train Epoch: 32 [12800/20000 (64%)]\tLoss: 2.158144\n",
            "Train Epoch: 32 [14400/20000 (72%)]\tLoss: 1.430664\n",
            "Train Epoch: 32 [16000/20000 (80%)]\tLoss: 1.650774\n",
            "Train Epoch: 32 [17600/20000 (88%)]\tLoss: 1.435222\n",
            "Train Epoch: 32 [19200/20000 (96%)]\tLoss: 1.815390\n",
            "Epoch : 32, Training accuracy : 78.91999816894531 %\n",
            "Epoch : 32, Validation accuracy : 87.80000305175781 %\n",
            "Train Epoch: 33 [0/20000 (0%)]\tLoss: 1.705730\n",
            "Train Epoch: 33 [1600/20000 (8%)]\tLoss: 1.824144\n",
            "Train Epoch: 33 [3200/20000 (16%)]\tLoss: 1.349553\n",
            "Train Epoch: 33 [4800/20000 (24%)]\tLoss: 2.237647\n",
            "Train Epoch: 33 [6400/20000 (32%)]\tLoss: 1.835491\n",
            "Train Epoch: 33 [8000/20000 (40%)]\tLoss: 1.895379\n",
            "Train Epoch: 33 [9600/20000 (48%)]\tLoss: 1.819094\n",
            "Train Epoch: 33 [11200/20000 (56%)]\tLoss: 1.962476\n",
            "Train Epoch: 33 [12800/20000 (64%)]\tLoss: 1.593564\n",
            "Train Epoch: 33 [14400/20000 (72%)]\tLoss: 1.961169\n",
            "Train Epoch: 33 [16000/20000 (80%)]\tLoss: 1.697304\n",
            "Train Epoch: 33 [17600/20000 (88%)]\tLoss: 1.451620\n",
            "Train Epoch: 33 [19200/20000 (96%)]\tLoss: 1.809945\n",
            "Epoch : 33, Training accuracy : 78.80999755859375 %\n",
            "Epoch : 33, Validation accuracy : 88.68000030517578 %\n",
            "Train Epoch: 34 [0/20000 (0%)]\tLoss: 1.664021\n",
            "Train Epoch: 34 [1600/20000 (8%)]\tLoss: 1.732158\n",
            "Train Epoch: 34 [3200/20000 (16%)]\tLoss: 1.802477\n",
            "Train Epoch: 34 [4800/20000 (24%)]\tLoss: 2.148476\n",
            "Train Epoch: 34 [6400/20000 (32%)]\tLoss: 2.149311\n",
            "Train Epoch: 34 [8000/20000 (40%)]\tLoss: 2.086264\n",
            "Train Epoch: 34 [9600/20000 (48%)]\tLoss: 2.252886\n",
            "Train Epoch: 34 [11200/20000 (56%)]\tLoss: 1.426944\n",
            "Train Epoch: 34 [12800/20000 (64%)]\tLoss: 1.698323\n",
            "Train Epoch: 34 [14400/20000 (72%)]\tLoss: 1.846580\n",
            "Train Epoch: 34 [16000/20000 (80%)]\tLoss: 2.015807\n",
            "Train Epoch: 34 [17600/20000 (88%)]\tLoss: 2.114922\n",
            "Train Epoch: 34 [19200/20000 (96%)]\tLoss: 2.050258\n",
            "Epoch : 34, Training accuracy : 78.94999694824219 %\n",
            "Epoch : 34, Validation accuracy : 88.68000030517578 %\n",
            "Train Epoch: 35 [0/20000 (0%)]\tLoss: 1.419505\n",
            "Train Epoch: 35 [1600/20000 (8%)]\tLoss: 2.051037\n",
            "Train Epoch: 35 [3200/20000 (16%)]\tLoss: 1.871396\n",
            "Train Epoch: 35 [4800/20000 (24%)]\tLoss: 3.015028\n",
            "Train Epoch: 35 [6400/20000 (32%)]\tLoss: 2.106653\n",
            "Train Epoch: 35 [8000/20000 (40%)]\tLoss: 1.680877\n",
            "Train Epoch: 35 [9600/20000 (48%)]\tLoss: 1.823571\n",
            "Train Epoch: 35 [11200/20000 (56%)]\tLoss: 1.760140\n",
            "Train Epoch: 35 [12800/20000 (64%)]\tLoss: 2.062312\n",
            "Train Epoch: 35 [14400/20000 (72%)]\tLoss: 2.215660\n",
            "Train Epoch: 35 [16000/20000 (80%)]\tLoss: 2.091049\n",
            "Train Epoch: 35 [17600/20000 (88%)]\tLoss: 1.552069\n",
            "Train Epoch: 35 [19200/20000 (96%)]\tLoss: 1.552644\n",
            "Epoch : 35, Training accuracy : 79.07499694824219 %\n",
            "Epoch : 35, Validation accuracy : 88.80000305175781 %\n",
            "Train Epoch: 36 [0/20000 (0%)]\tLoss: 2.330977\n",
            "Train Epoch: 36 [1600/20000 (8%)]\tLoss: 1.599019\n",
            "Train Epoch: 36 [3200/20000 (16%)]\tLoss: 1.938493\n",
            "Train Epoch: 36 [4800/20000 (24%)]\tLoss: 1.553705\n",
            "Train Epoch: 36 [6400/20000 (32%)]\tLoss: 1.673887\n",
            "Train Epoch: 36 [8000/20000 (40%)]\tLoss: 1.423386\n",
            "Train Epoch: 36 [9600/20000 (48%)]\tLoss: 1.642265\n",
            "Train Epoch: 36 [11200/20000 (56%)]\tLoss: 2.678935\n",
            "Train Epoch: 36 [12800/20000 (64%)]\tLoss: 2.730190\n",
            "Train Epoch: 36 [14400/20000 (72%)]\tLoss: 1.979779\n",
            "Train Epoch: 36 [16000/20000 (80%)]\tLoss: 1.681261\n",
            "Train Epoch: 36 [17600/20000 (88%)]\tLoss: 2.067071\n",
            "Train Epoch: 36 [19200/20000 (96%)]\tLoss: 1.981233\n",
            "Epoch : 36, Training accuracy : 78.94000244140625 %\n",
            "Epoch : 36, Validation accuracy : 88.63999938964844 %\n",
            "Train Epoch: 37 [0/20000 (0%)]\tLoss: 1.676169\n",
            "Train Epoch: 37 [1600/20000 (8%)]\tLoss: 1.411573\n",
            "Train Epoch: 37 [3200/20000 (16%)]\tLoss: 1.546742\n",
            "Train Epoch: 37 [4800/20000 (24%)]\tLoss: 1.550949\n",
            "Train Epoch: 37 [6400/20000 (32%)]\tLoss: 1.713215\n",
            "Train Epoch: 37 [8000/20000 (40%)]\tLoss: 1.827543\n",
            "Train Epoch: 37 [9600/20000 (48%)]\tLoss: 2.064988\n",
            "Train Epoch: 37 [11200/20000 (56%)]\tLoss: 1.580633\n",
            "Train Epoch: 37 [12800/20000 (64%)]\tLoss: 1.753382\n",
            "Train Epoch: 37 [14400/20000 (72%)]\tLoss: 1.764751\n",
            "Train Epoch: 37 [16000/20000 (80%)]\tLoss: 2.326016\n",
            "Train Epoch: 37 [17600/20000 (88%)]\tLoss: 1.772033\n",
            "Train Epoch: 37 [19200/20000 (96%)]\tLoss: 1.948167\n",
            "Epoch : 37, Training accuracy : 78.7249984741211 %\n",
            "Epoch : 37, Validation accuracy : 89.16000366210938 %\n",
            "Train Epoch: 38 [0/20000 (0%)]\tLoss: 2.603772\n",
            "Train Epoch: 38 [1600/20000 (8%)]\tLoss: 2.032569\n",
            "Train Epoch: 38 [3200/20000 (16%)]\tLoss: 1.685576\n",
            "Train Epoch: 38 [4800/20000 (24%)]\tLoss: 2.190724\n",
            "Train Epoch: 38 [6400/20000 (32%)]\tLoss: 2.346360\n",
            "Train Epoch: 38 [8000/20000 (40%)]\tLoss: 1.678246\n",
            "Train Epoch: 38 [9600/20000 (48%)]\tLoss: 1.701644\n",
            "Train Epoch: 38 [11200/20000 (56%)]\tLoss: 1.948665\n",
            "Train Epoch: 38 [12800/20000 (64%)]\tLoss: 1.715994\n",
            "Train Epoch: 38 [14400/20000 (72%)]\tLoss: 1.743847\n",
            "Train Epoch: 38 [16000/20000 (80%)]\tLoss: 1.584089\n",
            "Train Epoch: 38 [17600/20000 (88%)]\tLoss: 1.317591\n",
            "Train Epoch: 38 [19200/20000 (96%)]\tLoss: 1.817270\n",
            "Epoch : 38, Training accuracy : 79.45500183105469 %\n",
            "Epoch : 38, Validation accuracy : 88.44000244140625 %\n",
            "Train Epoch: 39 [0/20000 (0%)]\tLoss: 1.469715\n",
            "Train Epoch: 39 [1600/20000 (8%)]\tLoss: 1.683043\n",
            "Train Epoch: 39 [3200/20000 (16%)]\tLoss: 2.207421\n",
            "Train Epoch: 39 [4800/20000 (24%)]\tLoss: 1.956197\n",
            "Train Epoch: 39 [6400/20000 (32%)]\tLoss: 1.673950\n",
            "Train Epoch: 39 [8000/20000 (40%)]\tLoss: 1.788973\n",
            "Train Epoch: 39 [9600/20000 (48%)]\tLoss: 2.068786\n",
            "Train Epoch: 39 [11200/20000 (56%)]\tLoss: 1.407801\n",
            "Train Epoch: 39 [12800/20000 (64%)]\tLoss: 1.771476\n",
            "Train Epoch: 39 [14400/20000 (72%)]\tLoss: 1.940371\n",
            "Train Epoch: 39 [16000/20000 (80%)]\tLoss: 2.057322\n",
            "Train Epoch: 39 [17600/20000 (88%)]\tLoss: 2.138439\n",
            "Train Epoch: 39 [19200/20000 (96%)]\tLoss: 1.923348\n",
            "Epoch : 39, Training accuracy : 78.97000122070312 %\n",
            "Epoch : 39, Validation accuracy : 88.68000030517578 %\n",
            "Train Epoch: 40 [0/20000 (0%)]\tLoss: 1.298691\n",
            "Train Epoch: 40 [1600/20000 (8%)]\tLoss: 1.809416\n",
            "Train Epoch: 40 [3200/20000 (16%)]\tLoss: 1.555596\n",
            "Train Epoch: 40 [4800/20000 (24%)]\tLoss: 1.488345\n",
            "Train Epoch: 40 [6400/20000 (32%)]\tLoss: 2.414539\n",
            "Train Epoch: 40 [8000/20000 (40%)]\tLoss: 2.238948\n",
            "Train Epoch: 40 [9600/20000 (48%)]\tLoss: 1.411344\n",
            "Train Epoch: 40 [11200/20000 (56%)]\tLoss: 1.546314\n",
            "Train Epoch: 40 [12800/20000 (64%)]\tLoss: 1.582923\n",
            "Train Epoch: 40 [14400/20000 (72%)]\tLoss: 2.317859\n",
            "Train Epoch: 40 [16000/20000 (80%)]\tLoss: 2.220298\n",
            "Train Epoch: 40 [17600/20000 (88%)]\tLoss: 2.219946\n",
            "Train Epoch: 40 [19200/20000 (96%)]\tLoss: 1.586476\n",
            "Epoch : 40, Training accuracy : 79.05999755859375 %\n",
            "Epoch : 40, Validation accuracy : 88.4800033569336 %\n",
            "Train Epoch: 41 [0/20000 (0%)]\tLoss: 2.091050\n",
            "Train Epoch: 41 [1600/20000 (8%)]\tLoss: 1.914579\n",
            "Train Epoch: 41 [3200/20000 (16%)]\tLoss: 1.518672\n",
            "Train Epoch: 41 [4800/20000 (24%)]\tLoss: 2.067355\n",
            "Train Epoch: 41 [6400/20000 (32%)]\tLoss: 2.350256\n",
            "Train Epoch: 41 [8000/20000 (40%)]\tLoss: 1.609159\n",
            "Train Epoch: 41 [9600/20000 (48%)]\tLoss: 1.745992\n",
            "Train Epoch: 41 [11200/20000 (56%)]\tLoss: 1.993393\n",
            "Train Epoch: 41 [12800/20000 (64%)]\tLoss: 2.342027\n",
            "Train Epoch: 41 [14400/20000 (72%)]\tLoss: 1.812389\n",
            "Train Epoch: 41 [16000/20000 (80%)]\tLoss: 1.688438\n",
            "Train Epoch: 41 [17600/20000 (88%)]\tLoss: 1.728477\n",
            "Train Epoch: 41 [19200/20000 (96%)]\tLoss: 1.722954\n",
            "Epoch : 41, Training accuracy : 79.15499877929688 %\n",
            "Epoch : 41, Validation accuracy : 88.68000030517578 %\n",
            "Train Epoch: 42 [0/20000 (0%)]\tLoss: 1.802187\n",
            "Train Epoch: 42 [1600/20000 (8%)]\tLoss: 1.939225\n",
            "Train Epoch: 42 [3200/20000 (16%)]\tLoss: 1.807862\n",
            "Train Epoch: 42 [4800/20000 (24%)]\tLoss: 2.058346\n",
            "Train Epoch: 42 [6400/20000 (32%)]\tLoss: 1.553457\n",
            "Train Epoch: 42 [8000/20000 (40%)]\tLoss: 1.757998\n",
            "Train Epoch: 42 [9600/20000 (48%)]\tLoss: 1.534744\n",
            "Train Epoch: 42 [11200/20000 (56%)]\tLoss: 2.216465\n",
            "Train Epoch: 42 [12800/20000 (64%)]\tLoss: 2.194064\n",
            "Train Epoch: 42 [14400/20000 (72%)]\tLoss: 1.955722\n",
            "Train Epoch: 42 [16000/20000 (80%)]\tLoss: 1.922989\n",
            "Train Epoch: 42 [17600/20000 (88%)]\tLoss: 1.972048\n",
            "Train Epoch: 42 [19200/20000 (96%)]\tLoss: 1.952675\n",
            "Epoch : 42, Training accuracy : 79.44000244140625 %\n",
            "Epoch : 42, Validation accuracy : 88.5199966430664 %\n",
            "Train Epoch: 43 [0/20000 (0%)]\tLoss: 1.813746\n",
            "Train Epoch: 43 [1600/20000 (8%)]\tLoss: 1.579583\n",
            "Train Epoch: 43 [3200/20000 (16%)]\tLoss: 1.893557\n",
            "Train Epoch: 43 [4800/20000 (24%)]\tLoss: 1.952548\n",
            "Train Epoch: 43 [6400/20000 (32%)]\tLoss: 2.108443\n",
            "Train Epoch: 43 [8000/20000 (40%)]\tLoss: 1.552077\n",
            "Train Epoch: 43 [9600/20000 (48%)]\tLoss: 1.935923\n",
            "Train Epoch: 43 [11200/20000 (56%)]\tLoss: 2.130258\n",
            "Train Epoch: 43 [12800/20000 (64%)]\tLoss: 2.603140\n",
            "Train Epoch: 43 [14400/20000 (72%)]\tLoss: 2.066671\n",
            "Train Epoch: 43 [16000/20000 (80%)]\tLoss: 1.565872\n",
            "Train Epoch: 43 [17600/20000 (88%)]\tLoss: 1.940927\n",
            "Train Epoch: 43 [19200/20000 (96%)]\tLoss: 1.857122\n",
            "Epoch : 43, Training accuracy : 79.08000183105469 %\n",
            "Epoch : 43, Validation accuracy : 88.31999969482422 %\n",
            "Train Epoch: 44 [0/20000 (0%)]\tLoss: 1.538172\n",
            "Train Epoch: 44 [1600/20000 (8%)]\tLoss: 2.102952\n",
            "Train Epoch: 44 [3200/20000 (16%)]\tLoss: 1.404249\n",
            "Train Epoch: 44 [4800/20000 (24%)]\tLoss: 1.836460\n",
            "Train Epoch: 44 [6400/20000 (32%)]\tLoss: 1.830024\n",
            "Train Epoch: 44 [8000/20000 (40%)]\tLoss: 1.872709\n",
            "Train Epoch: 44 [9600/20000 (48%)]\tLoss: 1.935748\n",
            "Train Epoch: 44 [11200/20000 (56%)]\tLoss: 1.768305\n",
            "Train Epoch: 44 [12800/20000 (64%)]\tLoss: 1.813375\n",
            "Train Epoch: 44 [14400/20000 (72%)]\tLoss: 2.216152\n",
            "Train Epoch: 44 [16000/20000 (80%)]\tLoss: 2.055665\n",
            "Train Epoch: 44 [17600/20000 (88%)]\tLoss: 2.083813\n",
            "Train Epoch: 44 [19200/20000 (96%)]\tLoss: 1.415103\n",
            "Epoch : 44, Training accuracy : 79.51499938964844 %\n",
            "Epoch : 44, Validation accuracy : 88.23999786376953 %\n",
            "Train Epoch: 45 [0/20000 (0%)]\tLoss: 2.055830\n",
            "Train Epoch: 45 [1600/20000 (8%)]\tLoss: 1.815072\n",
            "Train Epoch: 45 [3200/20000 (16%)]\tLoss: 2.060562\n",
            "Train Epoch: 45 [4800/20000 (24%)]\tLoss: 2.033832\n",
            "Train Epoch: 45 [6400/20000 (32%)]\tLoss: 1.798330\n",
            "Train Epoch: 45 [8000/20000 (40%)]\tLoss: 1.762455\n",
            "Train Epoch: 45 [9600/20000 (48%)]\tLoss: 2.059729\n",
            "Train Epoch: 45 [11200/20000 (56%)]\tLoss: 2.100371\n",
            "Train Epoch: 45 [12800/20000 (64%)]\tLoss: 1.808817\n",
            "Train Epoch: 45 [14400/20000 (72%)]\tLoss: 1.705526\n",
            "Train Epoch: 45 [16000/20000 (80%)]\tLoss: 1.843277\n",
            "Train Epoch: 45 [17600/20000 (88%)]\tLoss: 1.547249\n",
            "Train Epoch: 45 [19200/20000 (96%)]\tLoss: 2.446661\n",
            "Epoch : 45, Training accuracy : 78.74500274658203 %\n",
            "Epoch : 45, Validation accuracy : 88.27999877929688 %\n",
            "Train Epoch: 46 [0/20000 (0%)]\tLoss: 1.656649\n",
            "Train Epoch: 46 [1600/20000 (8%)]\tLoss: 1.673545\n",
            "Train Epoch: 46 [3200/20000 (16%)]\tLoss: 1.798530\n",
            "Train Epoch: 46 [4800/20000 (24%)]\tLoss: 2.366258\n",
            "Train Epoch: 46 [6400/20000 (32%)]\tLoss: 1.549646\n",
            "Train Epoch: 46 [8000/20000 (40%)]\tLoss: 1.805382\n",
            "Train Epoch: 46 [9600/20000 (48%)]\tLoss: 2.194590\n",
            "Train Epoch: 46 [11200/20000 (56%)]\tLoss: 2.339231\n",
            "Train Epoch: 46 [12800/20000 (64%)]\tLoss: 2.308026\n",
            "Train Epoch: 46 [14400/20000 (72%)]\tLoss: 1.930805\n",
            "Train Epoch: 46 [16000/20000 (80%)]\tLoss: 1.670042\n",
            "Train Epoch: 46 [17600/20000 (88%)]\tLoss: 2.048217\n",
            "Train Epoch: 46 [19200/20000 (96%)]\tLoss: 1.846738\n",
            "Epoch : 46, Training accuracy : 78.55500030517578 %\n",
            "Epoch : 46, Validation accuracy : 88.4800033569336 %\n",
            "Train Epoch: 47 [0/20000 (0%)]\tLoss: 2.085149\n",
            "Train Epoch: 47 [1600/20000 (8%)]\tLoss: 1.760527\n",
            "Train Epoch: 47 [3200/20000 (16%)]\tLoss: 1.794424\n",
            "Train Epoch: 47 [4800/20000 (24%)]\tLoss: 1.811168\n",
            "Train Epoch: 47 [6400/20000 (32%)]\tLoss: 1.966016\n",
            "Train Epoch: 47 [8000/20000 (40%)]\tLoss: 1.945661\n",
            "Train Epoch: 47 [9600/20000 (48%)]\tLoss: 2.063345\n",
            "Train Epoch: 47 [11200/20000 (56%)]\tLoss: 1.666631\n",
            "Train Epoch: 47 [12800/20000 (64%)]\tLoss: 2.329280\n",
            "Train Epoch: 47 [14400/20000 (72%)]\tLoss: 1.917200\n",
            "Train Epoch: 47 [16000/20000 (80%)]\tLoss: 1.929609\n",
            "Train Epoch: 47 [17600/20000 (88%)]\tLoss: 2.163685\n",
            "Train Epoch: 47 [19200/20000 (96%)]\tLoss: 1.669101\n",
            "Epoch : 47, Training accuracy : 79.23500061035156 %\n",
            "Epoch : 47, Validation accuracy : 88.31999969482422 %\n",
            "Train Epoch: 48 [0/20000 (0%)]\tLoss: 1.678342\n",
            "Train Epoch: 48 [1600/20000 (8%)]\tLoss: 2.022833\n",
            "Train Epoch: 48 [3200/20000 (16%)]\tLoss: 1.682435\n",
            "Train Epoch: 48 [4800/20000 (24%)]\tLoss: 1.538179\n",
            "Train Epoch: 48 [6400/20000 (32%)]\tLoss: 1.893643\n",
            "Train Epoch: 48 [8000/20000 (40%)]\tLoss: 2.282906\n",
            "Train Epoch: 48 [9600/20000 (48%)]\tLoss: 2.461107\n",
            "Train Epoch: 48 [11200/20000 (56%)]\tLoss: 2.459106\n",
            "Train Epoch: 48 [12800/20000 (64%)]\tLoss: 2.433618\n",
            "Train Epoch: 48 [14400/20000 (72%)]\tLoss: 1.516172\n",
            "Train Epoch: 48 [16000/20000 (80%)]\tLoss: 1.926934\n",
            "Train Epoch: 48 [17600/20000 (88%)]\tLoss: 1.556015\n",
            "Train Epoch: 48 [19200/20000 (96%)]\tLoss: 1.561435\n",
            "Epoch : 48, Training accuracy : 79.33499908447266 %\n",
            "Epoch : 48, Validation accuracy : 88.80000305175781 %\n",
            "Train Epoch: 49 [0/20000 (0%)]\tLoss: 1.930387\n",
            "Train Epoch: 49 [1600/20000 (8%)]\tLoss: 2.253393\n",
            "Train Epoch: 49 [3200/20000 (16%)]\tLoss: 1.713762\n",
            "Train Epoch: 49 [4800/20000 (24%)]\tLoss: 1.623520\n",
            "Train Epoch: 49 [6400/20000 (32%)]\tLoss: 1.948375\n",
            "Train Epoch: 49 [8000/20000 (40%)]\tLoss: 1.539776\n",
            "Train Epoch: 49 [9600/20000 (48%)]\tLoss: 2.326581\n",
            "Train Epoch: 49 [11200/20000 (56%)]\tLoss: 1.788042\n",
            "Train Epoch: 49 [12800/20000 (64%)]\tLoss: 2.451703\n",
            "Train Epoch: 49 [14400/20000 (72%)]\tLoss: 2.057346\n",
            "Train Epoch: 49 [16000/20000 (80%)]\tLoss: 1.562270\n",
            "Train Epoch: 49 [17600/20000 (88%)]\tLoss: 1.800818\n",
            "Train Epoch: 49 [19200/20000 (96%)]\tLoss: 2.118367\n",
            "Epoch : 49, Training accuracy : 78.38500213623047 %\n",
            "Epoch : 49, Validation accuracy : 88.5999984741211 %\n",
            "Train Epoch: 50 [0/20000 (0%)]\tLoss: 2.256671\n",
            "Train Epoch: 50 [1600/20000 (8%)]\tLoss: 2.139745\n",
            "Train Epoch: 50 [3200/20000 (16%)]\tLoss: 1.826370\n",
            "Train Epoch: 50 [4800/20000 (24%)]\tLoss: 1.410470\n",
            "Train Epoch: 50 [6400/20000 (32%)]\tLoss: 2.068835\n",
            "Train Epoch: 50 [8000/20000 (40%)]\tLoss: 2.070030\n",
            "Train Epoch: 50 [9600/20000 (48%)]\tLoss: 1.673901\n",
            "Train Epoch: 50 [11200/20000 (56%)]\tLoss: 1.682013\n",
            "Train Epoch: 50 [12800/20000 (64%)]\tLoss: 2.319991\n",
            "Train Epoch: 50 [14400/20000 (72%)]\tLoss: 2.484415\n",
            "Train Epoch: 50 [16000/20000 (80%)]\tLoss: 2.058218\n",
            "Train Epoch: 50 [17600/20000 (88%)]\tLoss: 2.313509\n",
            "Train Epoch: 50 [19200/20000 (96%)]\tLoss: 2.006861\n",
            "Epoch : 50, Training accuracy : 79.58999633789062 %\n",
            "Epoch : 50, Validation accuracy : 88.68000030517578 %\n",
            "Train Epoch: 51 [0/20000 (0%)]\tLoss: 1.854838\n",
            "Train Epoch: 51 [1600/20000 (8%)]\tLoss: 2.190802\n",
            "Train Epoch: 51 [3200/20000 (16%)]\tLoss: 1.944100\n",
            "Train Epoch: 51 [4800/20000 (24%)]\tLoss: 1.917352\n",
            "Train Epoch: 51 [6400/20000 (32%)]\tLoss: 1.928674\n",
            "Train Epoch: 51 [8000/20000 (40%)]\tLoss: 1.792979\n",
            "Train Epoch: 51 [9600/20000 (48%)]\tLoss: 2.175927\n",
            "Train Epoch: 51 [11200/20000 (56%)]\tLoss: 2.529911\n",
            "Train Epoch: 51 [12800/20000 (64%)]\tLoss: 2.058862\n",
            "Train Epoch: 51 [14400/20000 (72%)]\tLoss: 2.137179\n",
            "Train Epoch: 51 [16000/20000 (80%)]\tLoss: 1.979389\n",
            "Train Epoch: 51 [17600/20000 (88%)]\tLoss: 1.692490\n",
            "Train Epoch: 51 [19200/20000 (96%)]\tLoss: 1.798984\n",
            "Epoch : 51, Training accuracy : 78.98500061035156 %\n",
            "Epoch : 51, Validation accuracy : 88.4800033569336 %\n",
            "Train Epoch: 52 [0/20000 (0%)]\tLoss: 2.443991\n",
            "Train Epoch: 52 [1600/20000 (8%)]\tLoss: 2.107314\n",
            "Train Epoch: 52 [3200/20000 (16%)]\tLoss: 2.446880\n",
            "Train Epoch: 52 [4800/20000 (24%)]\tLoss: 1.570958\n",
            "Train Epoch: 52 [6400/20000 (32%)]\tLoss: 1.424815\n",
            "Train Epoch: 52 [8000/20000 (40%)]\tLoss: 1.803080\n",
            "Train Epoch: 52 [9600/20000 (48%)]\tLoss: 1.791112\n",
            "Train Epoch: 52 [11200/20000 (56%)]\tLoss: 1.677760\n",
            "Train Epoch: 52 [12800/20000 (64%)]\tLoss: 2.081768\n",
            "Train Epoch: 52 [14400/20000 (72%)]\tLoss: 1.761138\n",
            "Train Epoch: 52 [16000/20000 (80%)]\tLoss: 2.099612\n",
            "Train Epoch: 52 [17600/20000 (88%)]\tLoss: 1.597523\n",
            "Train Epoch: 52 [19200/20000 (96%)]\tLoss: 2.743002\n",
            "Epoch : 52, Training accuracy : 78.91999816894531 %\n",
            "Epoch : 52, Validation accuracy : 88.5999984741211 %\n",
            "Train Epoch: 53 [0/20000 (0%)]\tLoss: 2.456847\n",
            "Train Epoch: 53 [1600/20000 (8%)]\tLoss: 2.353158\n",
            "Train Epoch: 53 [3200/20000 (16%)]\tLoss: 2.054353\n",
            "Train Epoch: 53 [4800/20000 (24%)]\tLoss: 2.436025\n",
            "Train Epoch: 53 [6400/20000 (32%)]\tLoss: 1.850622\n",
            "Train Epoch: 53 [8000/20000 (40%)]\tLoss: 1.424566\n",
            "Train Epoch: 53 [9600/20000 (48%)]\tLoss: 1.549003\n",
            "Train Epoch: 53 [11200/20000 (56%)]\tLoss: 1.921278\n",
            "Train Epoch: 53 [12800/20000 (64%)]\tLoss: 1.546569\n",
            "Train Epoch: 53 [14400/20000 (72%)]\tLoss: 2.025563\n",
            "Train Epoch: 53 [16000/20000 (80%)]\tLoss: 1.944602\n",
            "Train Epoch: 53 [17600/20000 (88%)]\tLoss: 2.424005\n",
            "Train Epoch: 53 [19200/20000 (96%)]\tLoss: 1.792637\n",
            "Epoch : 53, Training accuracy : 79.05999755859375 %\n",
            "Epoch : 53, Validation accuracy : 88.55999755859375 %\n",
            "Train Epoch: 54 [0/20000 (0%)]\tLoss: 1.983856\n",
            "Train Epoch: 54 [1600/20000 (8%)]\tLoss: 1.951897\n",
            "Train Epoch: 54 [3200/20000 (16%)]\tLoss: 2.458043\n",
            "Train Epoch: 54 [4800/20000 (24%)]\tLoss: 1.794276\n",
            "Train Epoch: 54 [6400/20000 (32%)]\tLoss: 1.697258\n",
            "Train Epoch: 54 [8000/20000 (40%)]\tLoss: 1.921303\n",
            "Train Epoch: 54 [9600/20000 (48%)]\tLoss: 2.002885\n",
            "Train Epoch: 54 [11200/20000 (56%)]\tLoss: 1.969070\n",
            "Train Epoch: 54 [12800/20000 (64%)]\tLoss: 1.929842\n",
            "Train Epoch: 54 [14400/20000 (72%)]\tLoss: 2.129147\n",
            "Train Epoch: 54 [16000/20000 (80%)]\tLoss: 1.939482\n",
            "Train Epoch: 54 [17600/20000 (88%)]\tLoss: 2.082654\n",
            "Train Epoch: 54 [19200/20000 (96%)]\tLoss: 1.570383\n",
            "Epoch : 54, Training accuracy : 78.78500366210938 %\n",
            "Epoch : 54, Validation accuracy : 88.4000015258789 %\n",
            "Train Epoch: 55 [0/20000 (0%)]\tLoss: 1.685221\n",
            "Train Epoch: 55 [1600/20000 (8%)]\tLoss: 1.592777\n",
            "Train Epoch: 55 [3200/20000 (16%)]\tLoss: 1.573114\n",
            "Train Epoch: 55 [4800/20000 (24%)]\tLoss: 1.789351\n",
            "Train Epoch: 55 [6400/20000 (32%)]\tLoss: 2.035289\n",
            "Train Epoch: 55 [8000/20000 (40%)]\tLoss: 2.358361\n",
            "Train Epoch: 55 [9600/20000 (48%)]\tLoss: 1.559396\n",
            "Train Epoch: 55 [11200/20000 (56%)]\tLoss: 1.924448\n",
            "Train Epoch: 55 [12800/20000 (64%)]\tLoss: 1.801116\n",
            "Train Epoch: 55 [14400/20000 (72%)]\tLoss: 1.788100\n",
            "Train Epoch: 55 [16000/20000 (80%)]\tLoss: 1.960047\n",
            "Train Epoch: 55 [17600/20000 (88%)]\tLoss: 1.937005\n",
            "Train Epoch: 55 [19200/20000 (96%)]\tLoss: 2.017058\n",
            "Epoch : 55, Training accuracy : 79.04499816894531 %\n",
            "Epoch : 55, Validation accuracy : 88.5199966430664 %\n",
            "Train Epoch: 56 [0/20000 (0%)]\tLoss: 1.791578\n",
            "Train Epoch: 56 [1600/20000 (8%)]\tLoss: 1.433311\n",
            "Train Epoch: 56 [3200/20000 (16%)]\tLoss: 1.538695\n",
            "Train Epoch: 56 [4800/20000 (24%)]\tLoss: 1.813862\n",
            "Train Epoch: 56 [6400/20000 (32%)]\tLoss: 2.367315\n",
            "Train Epoch: 56 [8000/20000 (40%)]\tLoss: 1.789218\n",
            "Train Epoch: 56 [9600/20000 (48%)]\tLoss: 1.316804\n",
            "Train Epoch: 56 [11200/20000 (56%)]\tLoss: 1.679390\n",
            "Train Epoch: 56 [12800/20000 (64%)]\tLoss: 2.063753\n",
            "Train Epoch: 56 [14400/20000 (72%)]\tLoss: 1.667797\n",
            "Train Epoch: 56 [16000/20000 (80%)]\tLoss: 1.822604\n",
            "Train Epoch: 56 [17600/20000 (88%)]\tLoss: 2.266847\n",
            "Train Epoch: 56 [19200/20000 (96%)]\tLoss: 1.808573\n",
            "Epoch : 56, Training accuracy : 78.90499877929688 %\n",
            "Epoch : 56, Validation accuracy : 88.63999938964844 %\n",
            "Train Epoch: 57 [0/20000 (0%)]\tLoss: 2.311573\n",
            "Train Epoch: 57 [1600/20000 (8%)]\tLoss: 2.023409\n",
            "Train Epoch: 57 [3200/20000 (16%)]\tLoss: 2.117572\n",
            "Train Epoch: 57 [4800/20000 (24%)]\tLoss: 1.409374\n",
            "Train Epoch: 57 [6400/20000 (32%)]\tLoss: 2.471665\n",
            "Train Epoch: 57 [8000/20000 (40%)]\tLoss: 1.930381\n",
            "Train Epoch: 57 [9600/20000 (48%)]\tLoss: 1.928758\n",
            "Train Epoch: 57 [11200/20000 (56%)]\tLoss: 1.905641\n",
            "Train Epoch: 57 [12800/20000 (64%)]\tLoss: 1.675047\n",
            "Train Epoch: 57 [14400/20000 (72%)]\tLoss: 1.697157\n",
            "Train Epoch: 57 [16000/20000 (80%)]\tLoss: 2.047353\n",
            "Train Epoch: 57 [17600/20000 (88%)]\tLoss: 1.924529\n",
            "Train Epoch: 57 [19200/20000 (96%)]\tLoss: 1.542724\n",
            "Epoch : 57, Training accuracy : 79.13500213623047 %\n",
            "Epoch : 57, Validation accuracy : 88.23999786376953 %\n",
            "Train Epoch: 58 [0/20000 (0%)]\tLoss: 1.794269\n",
            "Train Epoch: 58 [1600/20000 (8%)]\tLoss: 2.294980\n",
            "Train Epoch: 58 [3200/20000 (16%)]\tLoss: 1.542771\n",
            "Train Epoch: 58 [4800/20000 (24%)]\tLoss: 1.838656\n",
            "Train Epoch: 58 [6400/20000 (32%)]\tLoss: 2.228524\n",
            "Train Epoch: 58 [8000/20000 (40%)]\tLoss: 2.304850\n",
            "Train Epoch: 58 [9600/20000 (48%)]\tLoss: 1.836401\n",
            "Train Epoch: 58 [11200/20000 (56%)]\tLoss: 1.938863\n",
            "Train Epoch: 58 [12800/20000 (64%)]\tLoss: 1.542299\n",
            "Train Epoch: 58 [14400/20000 (72%)]\tLoss: 2.234771\n",
            "Train Epoch: 58 [16000/20000 (80%)]\tLoss: 1.919392\n",
            "Train Epoch: 58 [17600/20000 (88%)]\tLoss: 2.327687\n",
            "Train Epoch: 58 [19200/20000 (96%)]\tLoss: 1.781605\n",
            "Epoch : 58, Training accuracy : 79.0999984741211 %\n",
            "Epoch : 58, Validation accuracy : 88.31999969482422 %\n",
            "Train Epoch: 59 [0/20000 (0%)]\tLoss: 1.932691\n",
            "Train Epoch: 59 [1600/20000 (8%)]\tLoss: 1.917644\n",
            "Train Epoch: 59 [3200/20000 (16%)]\tLoss: 2.051082\n",
            "Train Epoch: 59 [4800/20000 (24%)]\tLoss: 1.803573\n",
            "Train Epoch: 59 [6400/20000 (32%)]\tLoss: 1.780328\n",
            "Train Epoch: 59 [8000/20000 (40%)]\tLoss: 1.691866\n",
            "Train Epoch: 59 [9600/20000 (48%)]\tLoss: 1.928402\n",
            "Train Epoch: 59 [11200/20000 (56%)]\tLoss: 2.311800\n",
            "Train Epoch: 59 [12800/20000 (64%)]\tLoss: 1.679667\n",
            "Train Epoch: 59 [14400/20000 (72%)]\tLoss: 1.553406\n",
            "Train Epoch: 59 [16000/20000 (80%)]\tLoss: 1.622299\n",
            "Train Epoch: 59 [17600/20000 (88%)]\tLoss: 1.662655\n",
            "Train Epoch: 59 [19200/20000 (96%)]\tLoss: 1.786627\n",
            "Epoch : 59, Training accuracy : 78.84500122070312 %\n",
            "Epoch : 59, Validation accuracy : 88.27999877929688 %\n",
            "Train Epoch: 60 [0/20000 (0%)]\tLoss: 1.918339\n",
            "Train Epoch: 60 [1600/20000 (8%)]\tLoss: 1.806188\n",
            "Train Epoch: 60 [3200/20000 (16%)]\tLoss: 2.296102\n",
            "Train Epoch: 60 [4800/20000 (24%)]\tLoss: 2.001075\n",
            "Train Epoch: 60 [6400/20000 (32%)]\tLoss: 1.713199\n",
            "Train Epoch: 60 [8000/20000 (40%)]\tLoss: 1.815565\n",
            "Train Epoch: 60 [9600/20000 (48%)]\tLoss: 1.442642\n",
            "Train Epoch: 60 [11200/20000 (56%)]\tLoss: 1.931143\n",
            "Train Epoch: 60 [12800/20000 (64%)]\tLoss: 1.411224\n",
            "Train Epoch: 60 [14400/20000 (72%)]\tLoss: 1.929738\n",
            "Train Epoch: 60 [16000/20000 (80%)]\tLoss: 2.043221\n",
            "Train Epoch: 60 [17600/20000 (88%)]\tLoss: 1.922676\n",
            "Train Epoch: 60 [19200/20000 (96%)]\tLoss: 2.257487\n",
            "Epoch : 60, Training accuracy : 78.78500366210938 %\n",
            "Epoch : 60, Validation accuracy : 88.91999816894531 %\n",
            "Train Epoch: 61 [0/20000 (0%)]\tLoss: 1.411542\n",
            "Train Epoch: 61 [1600/20000 (8%)]\tLoss: 2.354815\n",
            "Train Epoch: 61 [3200/20000 (16%)]\tLoss: 1.688578\n",
            "Train Epoch: 61 [4800/20000 (24%)]\tLoss: 2.237852\n",
            "Train Epoch: 61 [6400/20000 (32%)]\tLoss: 2.054487\n",
            "Train Epoch: 61 [8000/20000 (40%)]\tLoss: 1.951005\n",
            "Train Epoch: 61 [9600/20000 (48%)]\tLoss: 2.212557\n",
            "Train Epoch: 61 [11200/20000 (56%)]\tLoss: 2.200509\n",
            "Train Epoch: 61 [12800/20000 (64%)]\tLoss: 2.062182\n",
            "Train Epoch: 61 [14400/20000 (72%)]\tLoss: 1.803443\n",
            "Train Epoch: 61 [16000/20000 (80%)]\tLoss: 2.345478\n",
            "Train Epoch: 61 [17600/20000 (88%)]\tLoss: 2.312823\n",
            "Train Epoch: 61 [19200/20000 (96%)]\tLoss: 2.466423\n",
            "Epoch : 61, Training accuracy : 78.79499816894531 %\n",
            "Epoch : 61, Validation accuracy : 88.5999984741211 %\n",
            "Train Epoch: 62 [0/20000 (0%)]\tLoss: 1.672261\n",
            "Train Epoch: 62 [1600/20000 (8%)]\tLoss: 1.540815\n",
            "Train Epoch: 62 [3200/20000 (16%)]\tLoss: 2.041956\n",
            "Train Epoch: 62 [4800/20000 (24%)]\tLoss: 1.409674\n",
            "Train Epoch: 62 [6400/20000 (32%)]\tLoss: 1.806471\n",
            "Train Epoch: 62 [8000/20000 (40%)]\tLoss: 1.916424\n",
            "Train Epoch: 62 [9600/20000 (48%)]\tLoss: 1.591458\n",
            "Train Epoch: 62 [11200/20000 (56%)]\tLoss: 1.850886\n",
            "Train Epoch: 62 [12800/20000 (64%)]\tLoss: 2.047028\n",
            "Train Epoch: 62 [14400/20000 (72%)]\tLoss: 1.800385\n",
            "Train Epoch: 62 [16000/20000 (80%)]\tLoss: 1.791075\n",
            "Train Epoch: 62 [17600/20000 (88%)]\tLoss: 1.783654\n",
            "Train Epoch: 62 [19200/20000 (96%)]\tLoss: 1.794338\n",
            "Epoch : 62, Training accuracy : 79.36000061035156 %\n",
            "Epoch : 62, Validation accuracy : 88.0 %\n",
            "Train Epoch: 63 [0/20000 (0%)]\tLoss: 1.841488\n",
            "Train Epoch: 63 [1600/20000 (8%)]\tLoss: 2.046468\n",
            "Train Epoch: 63 [3200/20000 (16%)]\tLoss: 2.133085\n",
            "Train Epoch: 63 [4800/20000 (24%)]\tLoss: 1.922421\n",
            "Train Epoch: 63 [6400/20000 (32%)]\tLoss: 1.703327\n",
            "Train Epoch: 63 [8000/20000 (40%)]\tLoss: 1.783656\n",
            "Train Epoch: 63 [9600/20000 (48%)]\tLoss: 2.449355\n",
            "Train Epoch: 63 [11200/20000 (56%)]\tLoss: 2.226864\n",
            "Train Epoch: 63 [12800/20000 (64%)]\tLoss: 1.928236\n",
            "Train Epoch: 63 [14400/20000 (72%)]\tLoss: 1.680890\n",
            "Train Epoch: 63 [16000/20000 (80%)]\tLoss: 1.409219\n",
            "Train Epoch: 63 [17600/20000 (88%)]\tLoss: 1.918804\n",
            "Train Epoch: 63 [19200/20000 (96%)]\tLoss: 2.046230\n",
            "Epoch : 63, Training accuracy : 79.25499725341797 %\n",
            "Epoch : 63, Validation accuracy : 88.4800033569336 %\n",
            "Train Epoch: 64 [0/20000 (0%)]\tLoss: 2.193743\n",
            "Train Epoch: 64 [1600/20000 (8%)]\tLoss: 2.111477\n",
            "Train Epoch: 64 [3200/20000 (16%)]\tLoss: 1.874513\n",
            "Train Epoch: 64 [4800/20000 (24%)]\tLoss: 1.536536\n",
            "Train Epoch: 64 [6400/20000 (32%)]\tLoss: 1.938224\n",
            "Train Epoch: 64 [8000/20000 (40%)]\tLoss: 1.014127\n",
            "Train Epoch: 64 [9600/20000 (48%)]\tLoss: 1.785819\n",
            "Train Epoch: 64 [11200/20000 (56%)]\tLoss: 1.727211\n",
            "Train Epoch: 64 [12800/20000 (64%)]\tLoss: 1.244965\n",
            "Train Epoch: 64 [14400/20000 (72%)]\tLoss: 1.857631\n",
            "Train Epoch: 64 [16000/20000 (80%)]\tLoss: 2.218613\n",
            "Train Epoch: 64 [17600/20000 (88%)]\tLoss: 1.944122\n",
            "Train Epoch: 64 [19200/20000 (96%)]\tLoss: 1.717486\n",
            "Epoch : 64, Training accuracy : 79.62000274658203 %\n",
            "Epoch : 64, Validation accuracy : 88.4800033569336 %\n",
            "Train Epoch: 65 [0/20000 (0%)]\tLoss: 1.667214\n",
            "Train Epoch: 65 [1600/20000 (8%)]\tLoss: 2.183602\n",
            "Train Epoch: 65 [3200/20000 (16%)]\tLoss: 1.953962\n",
            "Train Epoch: 65 [4800/20000 (24%)]\tLoss: 2.133694\n",
            "Train Epoch: 65 [6400/20000 (32%)]\tLoss: 1.835780\n",
            "Train Epoch: 65 [8000/20000 (40%)]\tLoss: 1.801467\n",
            "Train Epoch: 65 [9600/20000 (48%)]\tLoss: 1.791467\n",
            "Train Epoch: 65 [11200/20000 (56%)]\tLoss: 1.703847\n",
            "Train Epoch: 65 [12800/20000 (64%)]\tLoss: 1.494290\n",
            "Train Epoch: 65 [14400/20000 (72%)]\tLoss: 2.316381\n",
            "Train Epoch: 65 [16000/20000 (80%)]\tLoss: 1.801518\n",
            "Train Epoch: 65 [17600/20000 (88%)]\tLoss: 1.304544\n",
            "Train Epoch: 65 [19200/20000 (96%)]\tLoss: 1.666147\n",
            "Epoch : 65, Training accuracy : 79.24500274658203 %\n",
            "Epoch : 65, Validation accuracy : 88.63999938964844 %\n",
            "Train Epoch: 66 [0/20000 (0%)]\tLoss: 1.530076\n",
            "Train Epoch: 66 [1600/20000 (8%)]\tLoss: 1.964621\n",
            "Train Epoch: 66 [3200/20000 (16%)]\tLoss: 1.939004\n",
            "Train Epoch: 66 [4800/20000 (24%)]\tLoss: 1.668825\n",
            "Train Epoch: 66 [6400/20000 (32%)]\tLoss: 1.891815\n",
            "Train Epoch: 66 [8000/20000 (40%)]\tLoss: 1.618065\n",
            "Train Epoch: 66 [9600/20000 (48%)]\tLoss: 1.924676\n",
            "Train Epoch: 66 [11200/20000 (56%)]\tLoss: 1.691850\n",
            "Train Epoch: 66 [12800/20000 (64%)]\tLoss: 1.917709\n",
            "Train Epoch: 66 [14400/20000 (72%)]\tLoss: 1.418970\n",
            "Train Epoch: 66 [16000/20000 (80%)]\tLoss: 1.562767\n",
            "Train Epoch: 66 [17600/20000 (88%)]\tLoss: 2.050371\n",
            "Train Epoch: 66 [19200/20000 (96%)]\tLoss: 2.051239\n",
            "Epoch : 66, Training accuracy : 79.16000366210938 %\n",
            "Epoch : 66, Validation accuracy : 88.36000061035156 %\n",
            "Train Epoch: 67 [0/20000 (0%)]\tLoss: 2.327918\n",
            "Train Epoch: 67 [1600/20000 (8%)]\tLoss: 2.202876\n",
            "Train Epoch: 67 [3200/20000 (16%)]\tLoss: 1.675581\n",
            "Train Epoch: 67 [4800/20000 (24%)]\tLoss: 1.947863\n",
            "Train Epoch: 67 [6400/20000 (32%)]\tLoss: 1.668508\n",
            "Train Epoch: 67 [8000/20000 (40%)]\tLoss: 2.060467\n",
            "Train Epoch: 67 [9600/20000 (48%)]\tLoss: 1.411065\n",
            "Train Epoch: 67 [11200/20000 (56%)]\tLoss: 1.797753\n",
            "Train Epoch: 67 [12800/20000 (64%)]\tLoss: 1.707997\n",
            "Train Epoch: 67 [14400/20000 (72%)]\tLoss: 1.851626\n",
            "Train Epoch: 67 [16000/20000 (80%)]\tLoss: 1.932931\n",
            "Train Epoch: 67 [17600/20000 (88%)]\tLoss: 2.055357\n",
            "Train Epoch: 67 [19200/20000 (96%)]\tLoss: 2.184474\n",
            "Epoch : 67, Training accuracy : 79.03500366210938 %\n",
            "Epoch : 67, Validation accuracy : 88.12000274658203 %\n",
            "Train Epoch: 68 [0/20000 (0%)]\tLoss: 2.188785\n",
            "Train Epoch: 68 [1600/20000 (8%)]\tLoss: 1.656865\n",
            "Train Epoch: 68 [3200/20000 (16%)]\tLoss: 2.303833\n",
            "Train Epoch: 68 [4800/20000 (24%)]\tLoss: 2.069289\n",
            "Train Epoch: 68 [6400/20000 (32%)]\tLoss: 1.664634\n",
            "Train Epoch: 68 [8000/20000 (40%)]\tLoss: 1.802169\n",
            "Train Epoch: 68 [9600/20000 (48%)]\tLoss: 1.568755\n",
            "Train Epoch: 68 [11200/20000 (56%)]\tLoss: 2.123381\n",
            "Train Epoch: 68 [12800/20000 (64%)]\tLoss: 1.531235\n",
            "Train Epoch: 68 [14400/20000 (72%)]\tLoss: 1.674760\n",
            "Train Epoch: 68 [16000/20000 (80%)]\tLoss: 1.926052\n",
            "Train Epoch: 68 [17600/20000 (88%)]\tLoss: 1.813931\n",
            "Train Epoch: 68 [19200/20000 (96%)]\tLoss: 2.096121\n",
            "Epoch : 68, Training accuracy : 78.79499816894531 %\n",
            "Epoch : 68, Validation accuracy : 88.5999984741211 %\n",
            "Train Epoch: 69 [0/20000 (0%)]\tLoss: 1.837668\n",
            "Train Epoch: 69 [1600/20000 (8%)]\tLoss: 2.325500\n",
            "Train Epoch: 69 [3200/20000 (16%)]\tLoss: 2.068647\n",
            "Train Epoch: 69 [4800/20000 (24%)]\tLoss: 2.337142\n",
            "Train Epoch: 69 [6400/20000 (32%)]\tLoss: 2.154812\n",
            "Train Epoch: 69 [8000/20000 (40%)]\tLoss: 1.695153\n",
            "Train Epoch: 69 [9600/20000 (48%)]\tLoss: 1.798306\n",
            "Train Epoch: 69 [11200/20000 (56%)]\tLoss: 1.409216\n",
            "Train Epoch: 69 [12800/20000 (64%)]\tLoss: 2.089688\n",
            "Train Epoch: 69 [14400/20000 (72%)]\tLoss: 1.922340\n",
            "Train Epoch: 69 [16000/20000 (80%)]\tLoss: 1.586788\n",
            "Train Epoch: 69 [17600/20000 (88%)]\tLoss: 1.673820\n",
            "Train Epoch: 69 [19200/20000 (96%)]\tLoss: 2.565161\n",
            "Epoch : 69, Training accuracy : 78.98500061035156 %\n",
            "Epoch : 69, Validation accuracy : 88.04000091552734 %\n",
            "Train Epoch: 70 [0/20000 (0%)]\tLoss: 1.809445\n",
            "Train Epoch: 70 [1600/20000 (8%)]\tLoss: 2.218985\n",
            "Train Epoch: 70 [3200/20000 (16%)]\tLoss: 1.793910\n",
            "Train Epoch: 70 [4800/20000 (24%)]\tLoss: 2.184577\n",
            "Train Epoch: 70 [6400/20000 (32%)]\tLoss: 1.680466\n",
            "Train Epoch: 70 [8000/20000 (40%)]\tLoss: 2.043695\n",
            "Train Epoch: 70 [9600/20000 (48%)]\tLoss: 1.802115\n",
            "Train Epoch: 70 [11200/20000 (56%)]\tLoss: 2.067675\n",
            "Train Epoch: 70 [12800/20000 (64%)]\tLoss: 1.798449\n",
            "Train Epoch: 70 [14400/20000 (72%)]\tLoss: 2.167748\n",
            "Train Epoch: 70 [16000/20000 (80%)]\tLoss: 1.822252\n",
            "Train Epoch: 70 [17600/20000 (88%)]\tLoss: 2.058312\n",
            "Train Epoch: 70 [19200/20000 (96%)]\tLoss: 1.796937\n",
            "Epoch : 70, Training accuracy : 79.0 %\n",
            "Epoch : 70, Validation accuracy : 88.68000030517578 %\n",
            "Train Epoch: 71 [0/20000 (0%)]\tLoss: 2.051456\n",
            "Train Epoch: 71 [1600/20000 (8%)]\tLoss: 1.545389\n",
            "Train Epoch: 71 [3200/20000 (16%)]\tLoss: 2.632303\n",
            "Train Epoch: 71 [4800/20000 (24%)]\tLoss: 1.799308\n",
            "Train Epoch: 71 [6400/20000 (32%)]\tLoss: 1.152102\n",
            "Train Epoch: 71 [8000/20000 (40%)]\tLoss: 1.974164\n",
            "Train Epoch: 71 [9600/20000 (48%)]\tLoss: 2.007414\n",
            "Train Epoch: 71 [11200/20000 (56%)]\tLoss: 1.557642\n",
            "Train Epoch: 71 [12800/20000 (64%)]\tLoss: 1.946024\n",
            "Train Epoch: 71 [14400/20000 (72%)]\tLoss: 1.892537\n",
            "Train Epoch: 71 [16000/20000 (80%)]\tLoss: 2.050823\n",
            "Train Epoch: 71 [17600/20000 (88%)]\tLoss: 2.212129\n",
            "Train Epoch: 71 [19200/20000 (96%)]\tLoss: 2.453157\n",
            "Epoch : 71, Training accuracy : 78.875 %\n",
            "Epoch : 71, Validation accuracy : 88.27999877929688 %\n",
            "Train Epoch: 72 [0/20000 (0%)]\tLoss: 1.666410\n",
            "Train Epoch: 72 [1600/20000 (8%)]\tLoss: 1.793025\n",
            "Train Epoch: 72 [3200/20000 (16%)]\tLoss: 2.216412\n",
            "Train Epoch: 72 [4800/20000 (24%)]\tLoss: 2.032692\n",
            "Train Epoch: 72 [6400/20000 (32%)]\tLoss: 1.957515\n",
            "Train Epoch: 72 [8000/20000 (40%)]\tLoss: 1.534903\n",
            "Train Epoch: 72 [9600/20000 (48%)]\tLoss: 2.181025\n",
            "Train Epoch: 72 [11200/20000 (56%)]\tLoss: 1.405051\n",
            "Train Epoch: 72 [12800/20000 (64%)]\tLoss: 1.540563\n",
            "Train Epoch: 72 [14400/20000 (72%)]\tLoss: 1.902483\n",
            "Train Epoch: 72 [16000/20000 (80%)]\tLoss: 2.434761\n",
            "Train Epoch: 72 [17600/20000 (88%)]\tLoss: 1.795657\n",
            "Train Epoch: 72 [19200/20000 (96%)]\tLoss: 1.558309\n",
            "Epoch : 72, Training accuracy : 79.0250015258789 %\n",
            "Epoch : 72, Validation accuracy : 88.08000183105469 %\n",
            "Train Epoch: 73 [0/20000 (0%)]\tLoss: 2.062942\n",
            "Train Epoch: 73 [1600/20000 (8%)]\tLoss: 2.057896\n",
            "Train Epoch: 73 [3200/20000 (16%)]\tLoss: 1.450572\n",
            "Train Epoch: 73 [4800/20000 (24%)]\tLoss: 1.800187\n",
            "Train Epoch: 73 [6400/20000 (32%)]\tLoss: 1.677126\n",
            "Train Epoch: 73 [8000/20000 (40%)]\tLoss: 1.558707\n",
            "Train Epoch: 73 [9600/20000 (48%)]\tLoss: 1.305536\n",
            "Train Epoch: 73 [11200/20000 (56%)]\tLoss: 1.669820\n",
            "Train Epoch: 73 [12800/20000 (64%)]\tLoss: 1.786874\n",
            "Train Epoch: 73 [14400/20000 (72%)]\tLoss: 2.172688\n",
            "Train Epoch: 73 [16000/20000 (80%)]\tLoss: 2.100803\n",
            "Train Epoch: 73 [17600/20000 (88%)]\tLoss: 1.683709\n",
            "Train Epoch: 73 [19200/20000 (96%)]\tLoss: 1.859188\n",
            "Epoch : 73, Training accuracy : 79.3550033569336 %\n",
            "Epoch : 73, Validation accuracy : 88.44000244140625 %\n",
            "Train Epoch: 74 [0/20000 (0%)]\tLoss: 1.631761\n",
            "Train Epoch: 74 [1600/20000 (8%)]\tLoss: 1.875794\n",
            "Train Epoch: 74 [3200/20000 (16%)]\tLoss: 2.056934\n",
            "Train Epoch: 74 [4800/20000 (24%)]\tLoss: 2.063709\n",
            "Train Epoch: 74 [6400/20000 (32%)]\tLoss: 1.980726\n",
            "Train Epoch: 74 [8000/20000 (40%)]\tLoss: 1.970284\n",
            "Train Epoch: 74 [9600/20000 (48%)]\tLoss: 1.633406\n",
            "Train Epoch: 74 [11200/20000 (56%)]\tLoss: 1.655324\n",
            "Train Epoch: 74 [12800/20000 (64%)]\tLoss: 1.549717\n",
            "Train Epoch: 74 [14400/20000 (72%)]\tLoss: 1.910947\n",
            "Train Epoch: 74 [16000/20000 (80%)]\tLoss: 1.404468\n",
            "Train Epoch: 74 [17600/20000 (88%)]\tLoss: 1.684822\n",
            "Train Epoch: 74 [19200/20000 (96%)]\tLoss: 1.567285\n",
            "Epoch : 74, Training accuracy : 78.92500305175781 %\n",
            "Epoch : 74, Validation accuracy : 88.5199966430664 %\n",
            "Train Epoch: 75 [0/20000 (0%)]\tLoss: 1.803081\n",
            "Train Epoch: 75 [1600/20000 (8%)]\tLoss: 1.819804\n",
            "Train Epoch: 75 [3200/20000 (16%)]\tLoss: 1.598824\n",
            "Train Epoch: 75 [4800/20000 (24%)]\tLoss: 1.664788\n",
            "Train Epoch: 75 [6400/20000 (32%)]\tLoss: 2.333708\n",
            "Train Epoch: 75 [8000/20000 (40%)]\tLoss: 1.590986\n",
            "Train Epoch: 75 [9600/20000 (48%)]\tLoss: 1.864192\n",
            "Train Epoch: 75 [11200/20000 (56%)]\tLoss: 1.788931\n",
            "Train Epoch: 75 [12800/20000 (64%)]\tLoss: 1.917758\n",
            "Train Epoch: 75 [14400/20000 (72%)]\tLoss: 1.533993\n",
            "Train Epoch: 75 [16000/20000 (80%)]\tLoss: 1.779968\n",
            "Train Epoch: 75 [17600/20000 (88%)]\tLoss: 2.464909\n",
            "Train Epoch: 75 [19200/20000 (96%)]\tLoss: 2.162154\n",
            "Epoch : 75, Training accuracy : 79.17500305175781 %\n",
            "Epoch : 75, Validation accuracy : 88.55999755859375 %\n",
            "Train Epoch: 76 [0/20000 (0%)]\tLoss: 1.918179\n",
            "Train Epoch: 76 [1600/20000 (8%)]\tLoss: 2.060142\n",
            "Train Epoch: 76 [3200/20000 (16%)]\tLoss: 1.803931\n",
            "Train Epoch: 76 [4800/20000 (24%)]\tLoss: 1.724585\n",
            "Train Epoch: 76 [6400/20000 (32%)]\tLoss: 2.051986\n",
            "Train Epoch: 76 [8000/20000 (40%)]\tLoss: 1.651772\n",
            "Train Epoch: 76 [9600/20000 (48%)]\tLoss: 1.806460\n",
            "Train Epoch: 76 [11200/20000 (56%)]\tLoss: 1.426419\n",
            "Train Epoch: 76 [12800/20000 (64%)]\tLoss: 2.069173\n",
            "Train Epoch: 76 [14400/20000 (72%)]\tLoss: 1.794426\n",
            "Train Epoch: 76 [16000/20000 (80%)]\tLoss: 1.782384\n",
            "Train Epoch: 76 [17600/20000 (88%)]\tLoss: 2.048239\n",
            "Train Epoch: 76 [19200/20000 (96%)]\tLoss: 2.074724\n",
            "Epoch : 76, Training accuracy : 79.19000244140625 %\n",
            "Epoch : 76, Validation accuracy : 88.36000061035156 %\n",
            "Train Epoch: 77 [0/20000 (0%)]\tLoss: 1.797730\n",
            "Train Epoch: 77 [1600/20000 (8%)]\tLoss: 1.856909\n",
            "Train Epoch: 77 [3200/20000 (16%)]\tLoss: 1.865219\n",
            "Train Epoch: 77 [4800/20000 (24%)]\tLoss: 1.916012\n",
            "Train Epoch: 77 [6400/20000 (32%)]\tLoss: 2.108239\n",
            "Train Epoch: 77 [8000/20000 (40%)]\tLoss: 2.195243\n",
            "Train Epoch: 77 [9600/20000 (48%)]\tLoss: 1.853704\n",
            "Train Epoch: 77 [11200/20000 (56%)]\tLoss: 2.200366\n",
            "Train Epoch: 77 [12800/20000 (64%)]\tLoss: 1.422235\n",
            "Train Epoch: 77 [14400/20000 (72%)]\tLoss: 1.967353\n",
            "Train Epoch: 77 [16000/20000 (80%)]\tLoss: 2.119177\n",
            "Train Epoch: 77 [17600/20000 (88%)]\tLoss: 1.652280\n",
            "Train Epoch: 77 [19200/20000 (96%)]\tLoss: 2.082007\n",
            "Epoch : 77, Training accuracy : 78.92500305175781 %\n",
            "Epoch : 77, Validation accuracy : 88.19999694824219 %\n",
            "Train Epoch: 78 [0/20000 (0%)]\tLoss: 1.697909\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-df36f2e9c805>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"drive/MyDrive/experiment/best_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m main(\n\u001b[0m\u001b[1;32m      7\u001b[0m          \u001b[0mdata_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"drive/MyDrive/mva_competition\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m          \u001b[0mexperiment_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"drive/MyDrive/experiment\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/jarry_cv_mva_competition/main.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(data_folder, experiment_folder, model_name, model_path, model_type, batch_size, num_workers, momentum, epochs, seed, lr_head, lr_body, saving_frequency, log_interval, fine_tune, optimizer, hidden_layers, weight_decay, dropout, tuning_layers)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/jarry_cv_mva_competition/main.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_loader, use_cuda, epoch, log_interval)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Optionally log detailed info (comment out for cleaner output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model_type = \"vit_large_patch16_224_in21k\"\n",
        "tuning_layers = 2\n",
        "model_name = \"vit_\" + model_type + f\"_fine_tuned_{tuning_layers}\"\n",
        "model_path = \"drive/MyDrive/experiment/best_\" + model_name + \".pth\"\n",
        "\n",
        "main(\n",
        "         data_folder=\"drive/MyDrive/mva_competition\",\n",
        "         experiment_folder=\"drive/MyDrive/experiment\",\n",
        "         model_name=model_name,\n",
        "         model_type=model_type,\n",
        "         model_path=model_path,\n",
        "         batch_size=32,\n",
        "         num_workers=2,\n",
        "         momentum=0.5,\n",
        "         epochs=100,\n",
        "         seed=42,\n",
        "         hidden_layers=None,\n",
        "         lr_head=1e-4,\n",
        "         lr_body=1e-4,\n",
        "         saving_frequency=5,\n",
        "         log_interval=50,\n",
        "         tuning_layers=tuning_layers,\n",
        "         fine_tune=True,\n",
        "         optimizer=\"AdamW\",\n",
        "         dropout=0.05\n",
        "     )\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b3144a80b1042dda016d9e01fdf3103": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d56fccd7db84637a8203a7d4fa9d570": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e954e61945d40eda4657faf0c961668",
            "placeholder": "​",
            "style": "IPY_MODEL_623168b0b48f4cfcaf8244ae9dbaf97e",
            "value": "model.safetensors: 100%"
          }
        },
        "1849590b8dc148ae918118b74ebc561f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e0c8349271748cdade8ae1a7e7ead2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1849590b8dc148ae918118b74ebc561f",
            "max": 1302790986,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2375169808264be8b02103b453cf47fd",
            "value": 1302790986
          }
        },
        "2375169808264be8b02103b453cf47fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e954e61945d40eda4657faf0c961668": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "623168b0b48f4cfcaf8244ae9dbaf97e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ecd7896d1ef4c75910585e94272cbf5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4fe9365c3dc4fb8a52c3d63c480a7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b3144a80b1042dda016d9e01fdf3103",
            "placeholder": "​",
            "style": "IPY_MODEL_f1e5e01b2ba647c5919c77df3cb665e4",
            "value": " 1.30G/1.30G [00:05&lt;00:00, 238MB/s]"
          }
        },
        "c7030379477643aba52627f22301e51a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d56fccd7db84637a8203a7d4fa9d570",
              "IPY_MODEL_1e0c8349271748cdade8ae1a7e7ead2b",
              "IPY_MODEL_a4fe9365c3dc4fb8a52c3d63c480a7c2"
            ],
            "layout": "IPY_MODEL_9ecd7896d1ef4c75910585e94272cbf5"
          }
        },
        "f1e5e01b2ba647c5919c77df3cb665e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}